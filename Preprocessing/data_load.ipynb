{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e6a469b-0fee-4a0b-814d-e4f83089aa2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "from skimage.transform import resize\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a5c054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_padding(image, target_height, target_width):\n",
    "    \"\"\"\n",
    "    Resize image with padding to maintain aspect ratio.\n",
    "\n",
    "    \"\"\"\n",
    "    # Calculate aspect ratio of original image\n",
    "    original_height, original_width, _ = image.shape\n",
    "    aspect_ratio = original_width / original_height\n",
    "    \n",
    "    # Resize image while preserving aspect ratio and fill with white pixels\n",
    "    if aspect_ratio > target_width / target_height:\n",
    "        # Image is wider, resize based on width\n",
    "        new_width = target_width\n",
    "        new_height = int(target_width / aspect_ratio)\n",
    "    elif aspect_ratio < target_width / target_height:\n",
    "        # Image is taller, resize based on height\n",
    "        new_height = target_height\n",
    "        new_width = int(aspect_ratio * target_height)\n",
    "    else:\n",
    "        # Image has the same aspect ratio as target\n",
    "        new_height = target_height\n",
    "        new_width = target_width\n",
    "    \n",
    "    resized_image = resize(image, (new_height, new_width), mode='constant') * 255  # Fill with white pixels\n",
    "    \n",
    "    # Pad to target dimensions with white pixels if necessary\n",
    "    padded_image = np.ones((target_height, target_width, 3), dtype=np.uint8) * 255  # Fill with white pixels\n",
    "    y_offset = (target_height - new_height) // 2\n",
    "    x_offset = (target_width - new_width) // 2\n",
    "    padded_image[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized_image\n",
    "    \n",
    "    return padded_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251db6e5-d369-4bfa-9554-b03ad97bdd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_transparency(im, bg_colour=(255, 255, 255)):\n",
    "    # Only process if image has transparency (http://stackoverflow.com/a/1963146)\n",
    "    if im.mode in ('RGBA', 'LA') or (im.mode == 'P' and 'transparency' in im.info):\n",
    "\n",
    "        # Need to convert to RGBA if LA format due to a bug in PIL (http://stackoverflow.com/a/1963146)\n",
    "        alpha = im.convert('RGBA').split()[-1]\n",
    "\n",
    "        # Create a new background image of our matt color.\n",
    "        # Must be RGBA because paste requires both images have the same format\n",
    "        # (http://stackoverflow.com/a/8720632  and  http://stackoverflow.com/a/9459208)\n",
    "        bg = Image.new(\"RGBA\", im.size, bg_colour + (255,))\n",
    "        bg.paste(im, mask=alpha)\n",
    "        return bg.convert('RGB')\n",
    "\n",
    "    else:\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eef1aaef-7cac-4061-bf64-96b5bfb2ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image_path, target_height, target_width):\n",
    "    with Image.open(path) as img:\n",
    "        # Remove transparency and resize the image\n",
    "        img = remove_transparency(img)\n",
    "        new_size = (224, 224) # Adjust the new size as needed\n",
    "        img = img.resize(new_size).convert('RGB')\n",
    "        img_array = np.array(img).astype(np.uint8)\n",
    "        \n",
    "        # Resize and pad the image\n",
    "        processed_image = resize_with_padding(img_array, target_height, target_width)\n",
    "\n",
    "    return processed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb537e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "trashbox_path = 'TrashBox/rm_deleted/'\n",
    "target_height = 224\n",
    "target_width = 224\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "allowed_extensions = {\".jpg\", \".png\"}\n",
    "\n",
    "for foldername in os.listdir(trashbox_path):\n",
    "    folder = os.path.join(trashbox_path, foldername)\n",
    "    for root, dirs, files in os.walk(folder):\n",
    "        # Check if the current folder contains any subfolders\n",
    "        subfolders = [d for d in dirs if os.path.isdir(os.path.join(root, d))]\n",
    "\n",
    "        # If there are no subfolders, collect images from the current folder\n",
    "        if not subfolders:\n",
    "            for file in files:\n",
    "                _, extension = os.path.splitext(file.lower())\n",
    "                if extension in allowed_extensions:\n",
    "                    image_paths.append(os.path.join(root, file))\n",
    "                    # Extract the label from the current subfolder\n",
    "                    labels.append(os.path.basename(root))\n",
    "        else:\n",
    "            # Iterate through each subfolder\n",
    "            for subfolder in subfolders:\n",
    "                subfolder_path = os.path.join(root, subfolder)\n",
    "                for file in os.listdir(subfolder_path):\n",
    "                    _, extension = os.path.splitext(file.lower())\n",
    "                    if extension in allowed_extensions:\n",
    "                        image_paths.append(os.path.join(subfolder_path, file))\n",
    "                        # Extract the label from the current subfolder\n",
    "                        labels.append(os.path.basename(subfolder_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b076fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_images = []\n",
    "for path in image_paths:\n",
    "    processed_image = process_image(path, target_height, target_width)\n",
    "    processed_images.append(processed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1a8c404-77e4-47d0-843e-e740ff10f597",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(processed_images)\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dbe0da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the arrays to files with pickle protocol 2\n",
    "with open('trashbox_224x224.npy', 'wb') as file:\n",
    "    np.save(file, X, allow_pickle=False)\n",
    "    \n",
    "with open('labels.npy', 'wb') as file:\n",
    "    np.save(file, y, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0815d85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23685, 224, 224, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e915e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23685,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76d4a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
