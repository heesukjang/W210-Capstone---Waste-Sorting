{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5-xHkiAEtA1X",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-07 21:48:04.538421: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-07 21:48:05.215241: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/transformers/utils/generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from torchvision import models, transforms\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import TensorDataset\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "import boto3\n",
    "import io\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.transforms import Normalize, Resize, ToTensor, Compose\n",
    "from PIL import Image\n",
    "from torchvision.transforms import ToPILImage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import ViTImageProcessor, ViTForImageClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "from PIL import Image\n",
    "from datasets import Dataset, ClassLabel, Features\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from transformers import TrainerCallback\n",
    "from copy import deepcopy\n",
    "\n",
    "# Function to download the npy file from S3\n",
    "def download_from_s3(bucket_name, object_key, aws_access_key_id, aws_secret_access_key):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "    response = s3.get_object(Bucket=bucket_name, Key=object_key)\n",
    "    content = response['Body'].read()\n",
    "    return np.load(io.BytesIO(content))\n",
    "\n",
    "# Function to upload the npy file to S3\n",
    "def upload_to_s3(bucket_name, object_key, data, aws_access_key_id, aws_secret_access_key):\n",
    "    s3 = boto3.client('s3', aws_access_key_id=aws_access_key_id, aws_secret_access_key=aws_secret_access_key)\n",
    "    with io.BytesIO() as data_stream:\n",
    "        np.save(data_stream, data)\n",
    "        data_stream.seek(0)\n",
    "        s3.upload_fileobj(data_stream, bucket_name, object_key)\n",
    "\n",
    "# S3 bucket information\n",
    "s3_bucket_name = \"capstone-efficient-waste-sorting-202402\"\n",
    "s3_input_object_key = \"npy/trashbox_224x224.npy\"\n",
    "# s3_output_object_key = \"npy/trashbox_augmented_224x224.npy\"\n",
    "\n",
    "# AWS credentials for S3\n",
    "aws_access_key_id = \"AKIA5P3O2NORKNC6DDWN\"\n",
    "aws_secret_access_key = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download image arrays from S3\n",
    "X_train = download_from_s3(s3_bucket_name, \"rgb_npy/train/rgb_224x224_train.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "y_train = download_from_s3(s3_bucket_name, \"rgb_npy/train/rgb_labels_train.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "X_val = download_from_s3(s3_bucket_name, \"rgb_npy/val/rgb_224x224_val.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "y_val = download_from_s3(s3_bucket_name, \"rgb_npy/val/rgb_labels_val.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "X_test = download_from_s3(s3_bucket_name, \"rgb_npy/test/rgb_224x224_test.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "y_test = download_from_s3(s3_bucket_name, \"rgb_npy/test/rgb_labels_test.npy\", aws_access_key_id, aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gp157FbutiYl"
   },
   "source": [
    "## ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hqQMH4nsta_9",
    "outputId": "f8c218b8-efa3-4b34-8732-6308f1a181e8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "electrical cables\n",
      "torch.Size([3, 224, 224])\n",
      "tensor(-1.) tensor(1.)\n",
      "tensor(0.) tensor(1.)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([27]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 768]) in the checkpoint and torch.Size([27, 768]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=768, out_features=27, bias=True)\n",
      "Parameter: vit.embeddings.cls_token, Requires Grad: False\n",
      "Parameter: vit.embeddings.position_embeddings, Requires Grad: False\n",
      "Parameter: vit.embeddings.patch_embeddings.projection.weight, Requires Grad: False\n",
      "Parameter: vit.embeddings.patch_embeddings.projection.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.attention.attention.query.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.attention.attention.query.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.attention.attention.key.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.attention.attention.key.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.attention.attention.value.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.attention.attention.value.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.attention.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.attention.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.intermediate.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.intermediate.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.layernorm_before.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.layernorm_before.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.layernorm_after.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.0.layernorm_after.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.attention.attention.query.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.attention.attention.query.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.attention.attention.key.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.attention.attention.key.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.attention.attention.value.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.attention.attention.value.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.attention.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.attention.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.intermediate.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.intermediate.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.layernorm_before.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.layernorm_before.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.layernorm_after.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.1.layernorm_after.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.attention.attention.query.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.attention.attention.query.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.attention.attention.key.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.attention.attention.key.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.attention.attention.value.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.attention.attention.value.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.attention.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.attention.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.intermediate.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.intermediate.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.layernorm_before.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.layernorm_before.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.layernorm_after.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.2.layernorm_after.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.attention.attention.query.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.attention.attention.query.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.attention.attention.key.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.attention.attention.key.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.attention.attention.value.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.attention.attention.value.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.attention.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.attention.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.intermediate.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.intermediate.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.layernorm_before.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.layernorm_before.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.layernorm_after.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.3.layernorm_after.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.attention.attention.query.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.attention.attention.query.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.attention.attention.key.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.attention.attention.key.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.attention.attention.value.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.attention.attention.value.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.attention.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.attention.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.intermediate.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.intermediate.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.layernorm_before.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.layernorm_before.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.layernorm_after.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.4.layernorm_after.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.attention.attention.query.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.attention.attention.query.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.attention.attention.key.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.attention.attention.key.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.attention.attention.value.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.attention.attention.value.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.attention.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.attention.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.intermediate.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.intermediate.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.layernorm_before.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.layernorm_before.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.layernorm_after.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.5.layernorm_after.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.attention.attention.query.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.attention.attention.query.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.attention.attention.key.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.attention.attention.key.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.attention.attention.value.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.attention.attention.value.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.attention.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.attention.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.intermediate.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.intermediate.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.layernorm_before.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.layernorm_before.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.layernorm_after.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.6.layernorm_after.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.attention.attention.query.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.attention.attention.query.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.attention.attention.key.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.attention.attention.key.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.attention.attention.value.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.attention.attention.value.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.attention.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.attention.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.intermediate.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.intermediate.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.layernorm_before.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.layernorm_before.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.layernorm_after.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.7.layernorm_after.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.attention.attention.query.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.attention.attention.query.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.attention.attention.key.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.attention.attention.key.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.attention.attention.value.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.attention.attention.value.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.attention.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.attention.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.intermediate.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.intermediate.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.output.dense.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.output.dense.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.layernorm_before.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.layernorm_before.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.layernorm_after.weight, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.8.layernorm_after.bias, Requires Grad: False\n",
      "Parameter: vit.encoder.layer.9.attention.attention.query.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.attention.attention.query.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.attention.attention.key.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.attention.attention.key.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.attention.attention.value.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.attention.attention.value.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.attention.output.dense.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.attention.output.dense.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.intermediate.dense.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.intermediate.dense.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.output.dense.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.output.dense.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.layernorm_before.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.layernorm_before.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.layernorm_after.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.9.layernorm_after.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.attention.attention.query.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.attention.attention.query.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.attention.attention.key.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.attention.attention.key.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.attention.attention.value.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.attention.attention.value.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.attention.output.dense.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.attention.output.dense.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.intermediate.dense.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.intermediate.dense.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.output.dense.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.output.dense.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.layernorm_before.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.layernorm_before.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.layernorm_after.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.10.layernorm_after.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.attention.attention.query.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.attention.attention.query.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.attention.attention.key.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.attention.attention.key.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.attention.attention.value.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.attention.attention.value.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.attention.output.dense.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.attention.output.dense.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.intermediate.dense.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.intermediate.dense.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.output.dense.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.output.dense.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.layernorm_before.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.layernorm_before.bias, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.layernorm_after.weight, Requires Grad: True\n",
      "Parameter: vit.encoder.layer.11.layernorm_after.bias, Requires Grad: True\n",
      "Parameter: vit.layernorm.weight, Requires Grad: True\n",
      "Parameter: vit.layernorm.bias, Requires Grad: True\n",
      "Parameter: classifier.weight, Requires Grad: True\n",
      "Parameter: classifier.bias, Requires Grad: True\n"
     ]
    }
   ],
   "source": [
    "# took 50 seconds\n",
    "# from PIL import Image\n",
    "# from datasets import Dataset, ClassLabel, Features\n",
    "\n",
    "# Convert pixel values to PIL images\n",
    "# sample_size_train = 5000\n",
    "# sample_size_val = 1000\n",
    "# sample_size_test = 1000\n",
    "# sample_size_train = 650\n",
    "# sample_size_val = 590\n",
    "# sample_size_test = 500\n",
    "# X_train_images = [Image.fromarray(x.astype(np.uint8)) for x in X_train[:sample_size_train]]\n",
    "# X_val_images = [Image.fromarray(x.astype(np.uint8)) for x in X_val[:sample_size_val]]\n",
    "# X_test_images = [Image.fromarray(x.astype(np.uint8)) for x in X_test[:sample_size_test]]\n",
    "X_train_images = [Image.fromarray((x * 255).astype(np.uint8)) for x in X_train] # need to multiply by 255 for rgb\n",
    "X_val_images = [Image.fromarray((x * 255).astype(np.uint8)) for x in X_val] # need to multiply by 255 for rgb\n",
    "X_test_images = [Image.fromarray((x * 255).astype(np.uint8)) for x in X_test] # need to multiply by 255 for rgb\n",
    "\n",
    "# Convert class labels to ClassLabel format\n",
    "label_class = ClassLabel(names=['battery', 'beverage cans', 'cardboard', 'cigarette butt',\n",
    "       'construction scrap', 'electrical cables', 'electronic chips',\n",
    "       'glass', 'gloves', 'laptops', 'masks', 'medicines',\n",
    "       'metal containers', 'news paper', 'other metal objects', 'paper',\n",
    "       'paper_cups', 'plastic bags', 'plastic bottles',\n",
    "       'plastic containers', 'plastic_cups', 'small appliances',\n",
    "       'smartphones', 'spray cans', 'syringe', 'tetra pak', 'trash'])\n",
    "y_train_labels = label_class.str2int(y_train)\n",
    "y_val_labels = label_class.str2int(y_val)\n",
    "y_test_labels = label_class.str2int(y_test)\n",
    "# y_train_labels = label_class.str2int(y_train[:sample_size_train])\n",
    "# y_val_labels = label_class.str2int(y_val[:sample_size_val])\n",
    "# y_test_labels = label_class.str2int(y_test[:sample_size_test])\n",
    "\n",
    "train_dataset_dict = {\n",
    "    \"img\": X_train_images,\n",
    "    \"label\": y_train_labels\n",
    "}\n",
    "val_dataset_dict = {\n",
    "    \"img\": X_val_images,\n",
    "    \"label\": y_val_labels\n",
    "}\n",
    "test_dataset_dict = {\n",
    "    \"img\": X_test_images,\n",
    "    \"label\": y_test_labels\n",
    "}\n",
    "\n",
    "trainds = Dataset.from_dict(train_dataset_dict, split='train')\n",
    "valds = Dataset.from_dict(val_dataset_dict, split='val')\n",
    "testds = Dataset.from_dict(test_dataset_dict, split='test')\n",
    "\n",
    "trainds, valds, testds\n",
    "\n",
    "trainds.features, trainds.num_rows, trainds[0]\n",
    "\n",
    "# Create id2label and label2id mappings\n",
    "itos = dict((k,v) for k,v in enumerate(label_class.names)) # id2label\n",
    "stoi = dict((v,k) for k,v in enumerate(label_class.names)) # label2id\n",
    "itos, stoi\n",
    "\n",
    "img, lab = trainds[0]['img'], itos[trainds[0]['label']]\n",
    "print(lab)\n",
    "img\n",
    "\n",
    "model_name = \"google/vit-base-patch16-224\"\n",
    "processor = ViTImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "mu, sigma = processor.image_mean, processor.image_std\n",
    "size = processor.size\n",
    "size\n",
    "\n",
    "norm = Normalize(mean=mu, std=sigma)\n",
    "\n",
    "_transf = Compose([\n",
    "    Resize(size['height']),\n",
    "    ToTensor(),\n",
    "    norm\n",
    "])\n",
    "\n",
    "def transf(arg):\n",
    "    arg['pixels'] = [_transf(image.convert('RGB')) for image in arg['img']]\n",
    "    return arg\n",
    "\n",
    "trainds.set_transform(transf)\n",
    "valds.set_transform(transf)\n",
    "testds.set_transform(transf)\n",
    "\n",
    "trainds[0].keys()\n",
    "\n",
    "ex = trainds[0]['pixels']\n",
    "print(ex.shape)\n",
    "print(torch.min(ex), torch.max(ex))\n",
    "ex = (ex+1)/2\n",
    "print(torch.min(ex), torch.max(ex))\n",
    "\n",
    "exi = ToPILImage()(ex)\n",
    "plt.imshow(exi)\n",
    "plt.show()\n",
    "\n",
    "#The model was originally trained for 1000 classes, it needs to be fine tuned again with 27 output classes\n",
    "model = ViTForImageClassification.from_pretrained(model_name, num_labels=27,  ignore_mismatched_sizes=True, id2label=itos, label2id=stoi)\n",
    "print(model.classifier)\n",
    "\n",
    "model.config.num_hidden_layers\n",
    "\n",
    "len(list(model.parameters()))\n",
    "\n",
    "(len(list(model.parameters())) // 4) * 3 - 2\n",
    "\n",
    "# FREEZE BOTTOM 75% OF LAYERS\n",
    "\n",
    "# Determine the total number of layers in the model\n",
    "total_layers = len(list(model.parameters()))\n",
    "\n",
    "# Calculate the index to split the layers\n",
    "split_index = (total_layers // 4) * 3 -  2 # make the cutoff so that all of layer 9 is unfrozen\n",
    "\n",
    "# Freeze the bottom 75% of layers (including embedding and encoder layers)\n",
    "for i, param in enumerate(model.parameters()):\n",
    "    if i < split_index:\n",
    "        param.requires_grad = False\n",
    "\n",
    "# Check which layers are frozen\n",
    "# Iterate through the model's parameters and print whether each parameter is frozen or not\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter: {name}, Requires Grad: {param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uGgR1q9NteOu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1608' max='1608' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1608/1608 27:28, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.023500</td>\n",
       "      <td>2.636230</td>\n",
       "      <td>0.350746</td>\n",
       "      <td>0.217285</td>\n",
       "      <td>0.221169</td>\n",
       "      <td>0.208470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.023500</td>\n",
       "      <td>2.024670</td>\n",
       "      <td>0.603919</td>\n",
       "      <td>0.560642</td>\n",
       "      <td>0.408166</td>\n",
       "      <td>0.428220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.325300</td>\n",
       "      <td>2.036111</td>\n",
       "      <td>0.600407</td>\n",
       "      <td>0.525792</td>\n",
       "      <td>0.407099</td>\n",
       "      <td>0.426049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.325300</td>\n",
       "      <td>1.582266</td>\n",
       "      <td>0.697065</td>\n",
       "      <td>0.722500</td>\n",
       "      <td>0.503516</td>\n",
       "      <td>0.532110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.799300</td>\n",
       "      <td>1.606166</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.722304</td>\n",
       "      <td>0.535711</td>\n",
       "      <td>0.568964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.799300</td>\n",
       "      <td>1.275895</td>\n",
       "      <td>0.756702</td>\n",
       "      <td>0.798970</td>\n",
       "      <td>0.589519</td>\n",
       "      <td>0.627733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.426400</td>\n",
       "      <td>1.309693</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>0.799958</td>\n",
       "      <td>0.616572</td>\n",
       "      <td>0.656012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.426400</td>\n",
       "      <td>1.065783</td>\n",
       "      <td>0.801069</td>\n",
       "      <td>0.822323</td>\n",
       "      <td>0.657411</td>\n",
       "      <td>0.693944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.169900</td>\n",
       "      <td>1.106840</td>\n",
       "      <td>0.796472</td>\n",
       "      <td>0.814526</td>\n",
       "      <td>0.685121</td>\n",
       "      <td>0.718695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.169900</td>\n",
       "      <td>0.919934</td>\n",
       "      <td>0.827876</td>\n",
       "      <td>0.865115</td>\n",
       "      <td>0.727595</td>\n",
       "      <td>0.760877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.965976</td>\n",
       "      <td>0.819539</td>\n",
       "      <td>0.863445</td>\n",
       "      <td>0.723827</td>\n",
       "      <td>0.754501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.993000</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.843824</td>\n",
       "      <td>0.871454</td>\n",
       "      <td>0.755823</td>\n",
       "      <td>0.788274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.869101</td>\n",
       "      <td>0.832429</td>\n",
       "      <td>0.863119</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.773180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.749464</td>\n",
       "      <td>0.856719</td>\n",
       "      <td>0.878892</td>\n",
       "      <td>0.779808</td>\n",
       "      <td>0.811462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.785200</td>\n",
       "      <td>0.802795</td>\n",
       "      <td>0.845997</td>\n",
       "      <td>0.868163</td>\n",
       "      <td>0.771436</td>\n",
       "      <td>0.799145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.785200</td>\n",
       "      <td>0.702273</td>\n",
       "      <td>0.865965</td>\n",
       "      <td>0.883094</td>\n",
       "      <td>0.797604</td>\n",
       "      <td>0.826853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.726600</td>\n",
       "      <td>0.757980</td>\n",
       "      <td>0.856852</td>\n",
       "      <td>0.873692</td>\n",
       "      <td>0.787728</td>\n",
       "      <td>0.813796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.726600</td>\n",
       "      <td>0.671831</td>\n",
       "      <td>0.870716</td>\n",
       "      <td>0.885149</td>\n",
       "      <td>0.806206</td>\n",
       "      <td>0.834071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>0.729187</td>\n",
       "      <td>0.858887</td>\n",
       "      <td>0.873608</td>\n",
       "      <td>0.791103</td>\n",
       "      <td>0.815521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.687600</td>\n",
       "      <td>0.654830</td>\n",
       "      <td>0.873855</td>\n",
       "      <td>0.886124</td>\n",
       "      <td>0.812053</td>\n",
       "      <td>0.838917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.663300</td>\n",
       "      <td>0.713208</td>\n",
       "      <td>0.861601</td>\n",
       "      <td>0.875867</td>\n",
       "      <td>0.795917</td>\n",
       "      <td>0.819816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.663300</td>\n",
       "      <td>0.649350</td>\n",
       "      <td>0.874364</td>\n",
       "      <td>0.885557</td>\n",
       "      <td>0.813575</td>\n",
       "      <td>0.839964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.651500</td>\n",
       "      <td>0.708055</td>\n",
       "      <td>0.862280</td>\n",
       "      <td>0.874880</td>\n",
       "      <td>0.796986</td>\n",
       "      <td>0.820071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1596' max='1596' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1596/1596 31:07, Epoch 14/14]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>0.519155</td>\n",
       "      <td>0.886703</td>\n",
       "      <td>0.874125</td>\n",
       "      <td>0.848293</td>\n",
       "      <td>0.857487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.545100</td>\n",
       "      <td>0.337680</td>\n",
       "      <td>0.923142</td>\n",
       "      <td>0.918610</td>\n",
       "      <td>0.893473</td>\n",
       "      <td>0.904658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.434303</td>\n",
       "      <td>0.892130</td>\n",
       "      <td>0.878026</td>\n",
       "      <td>0.858792</td>\n",
       "      <td>0.865326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.397000</td>\n",
       "      <td>0.274558</td>\n",
       "      <td>0.936885</td>\n",
       "      <td>0.929765</td>\n",
       "      <td>0.915230</td>\n",
       "      <td>0.921761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.315500</td>\n",
       "      <td>0.389248</td>\n",
       "      <td>0.899593</td>\n",
       "      <td>0.886331</td>\n",
       "      <td>0.872220</td>\n",
       "      <td>0.876879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.315500</td>\n",
       "      <td>0.230198</td>\n",
       "      <td>0.947404</td>\n",
       "      <td>0.941649</td>\n",
       "      <td>0.928183</td>\n",
       "      <td>0.934384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.362483</td>\n",
       "      <td>0.903664</td>\n",
       "      <td>0.892069</td>\n",
       "      <td>0.876852</td>\n",
       "      <td>0.882241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.261800</td>\n",
       "      <td>0.197129</td>\n",
       "      <td>0.955887</td>\n",
       "      <td>0.950824</td>\n",
       "      <td>0.941249</td>\n",
       "      <td>0.945590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.345529</td>\n",
       "      <td>0.904342</td>\n",
       "      <td>0.895159</td>\n",
       "      <td>0.878546</td>\n",
       "      <td>0.884466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.221200</td>\n",
       "      <td>0.171752</td>\n",
       "      <td>0.962589</td>\n",
       "      <td>0.958949</td>\n",
       "      <td>0.949411</td>\n",
       "      <td>0.953793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.332768</td>\n",
       "      <td>0.905020</td>\n",
       "      <td>0.894841</td>\n",
       "      <td>0.879223</td>\n",
       "      <td>0.884942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.192500</td>\n",
       "      <td>0.152078</td>\n",
       "      <td>0.969121</td>\n",
       "      <td>0.966064</td>\n",
       "      <td>0.961273</td>\n",
       "      <td>0.963476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.323989</td>\n",
       "      <td>0.907734</td>\n",
       "      <td>0.892394</td>\n",
       "      <td>0.882515</td>\n",
       "      <td>0.885305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.167800</td>\n",
       "      <td>0.136902</td>\n",
       "      <td>0.973193</td>\n",
       "      <td>0.969928</td>\n",
       "      <td>0.966253</td>\n",
       "      <td>0.967908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.318245</td>\n",
       "      <td>0.907056</td>\n",
       "      <td>0.891539</td>\n",
       "      <td>0.882507</td>\n",
       "      <td>0.885001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.149000</td>\n",
       "      <td>0.125035</td>\n",
       "      <td>0.975908</td>\n",
       "      <td>0.973640</td>\n",
       "      <td>0.969183</td>\n",
       "      <td>0.971249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.313757</td>\n",
       "      <td>0.908412</td>\n",
       "      <td>0.893554</td>\n",
       "      <td>0.884476</td>\n",
       "      <td>0.886890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.116019</td>\n",
       "      <td>0.979046</td>\n",
       "      <td>0.976777</td>\n",
       "      <td>0.973354</td>\n",
       "      <td>0.974960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.310474</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.893959</td>\n",
       "      <td>0.886081</td>\n",
       "      <td>0.888081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.123900</td>\n",
       "      <td>0.109325</td>\n",
       "      <td>0.980913</td>\n",
       "      <td>0.978907</td>\n",
       "      <td>0.975330</td>\n",
       "      <td>0.977018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.308144</td>\n",
       "      <td>0.907734</td>\n",
       "      <td>0.892652</td>\n",
       "      <td>0.882625</td>\n",
       "      <td>0.885593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.114800</td>\n",
       "      <td>0.104789</td>\n",
       "      <td>0.982440</td>\n",
       "      <td>0.980528</td>\n",
       "      <td>0.977852</td>\n",
       "      <td>0.979109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.306464</td>\n",
       "      <td>0.906377</td>\n",
       "      <td>0.891594</td>\n",
       "      <td>0.880582</td>\n",
       "      <td>0.883956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.108700</td>\n",
       "      <td>0.102143</td>\n",
       "      <td>0.982864</td>\n",
       "      <td>0.980934</td>\n",
       "      <td>0.978272</td>\n",
       "      <td>0.979533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.305580</td>\n",
       "      <td>0.906377</td>\n",
       "      <td>0.892157</td>\n",
       "      <td>0.880582</td>\n",
       "      <td>0.884290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.104400</td>\n",
       "      <td>0.101276</td>\n",
       "      <td>0.983118</td>\n",
       "      <td>0.981090</td>\n",
       "      <td>0.978534</td>\n",
       "      <td>0.979742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.305363</td>\n",
       "      <td>0.906377</td>\n",
       "      <td>0.892157</td>\n",
       "      <td>0.880582</td>\n",
       "      <td>0.884290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='828' max='828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [828/828 24:17, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.307026</td>\n",
       "      <td>0.906377</td>\n",
       "      <td>0.892207</td>\n",
       "      <td>0.880582</td>\n",
       "      <td>0.884288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.114600</td>\n",
       "      <td>0.095282</td>\n",
       "      <td>0.984561</td>\n",
       "      <td>0.983116</td>\n",
       "      <td>0.980173</td>\n",
       "      <td>0.981570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.303999</td>\n",
       "      <td>0.907056</td>\n",
       "      <td>0.893008</td>\n",
       "      <td>0.880793</td>\n",
       "      <td>0.884848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102800</td>\n",
       "      <td>0.087455</td>\n",
       "      <td>0.986427</td>\n",
       "      <td>0.984743</td>\n",
       "      <td>0.982739</td>\n",
       "      <td>0.983682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.300707</td>\n",
       "      <td>0.907056</td>\n",
       "      <td>0.892503</td>\n",
       "      <td>0.881001</td>\n",
       "      <td>0.884825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.080769</td>\n",
       "      <td>0.988124</td>\n",
       "      <td>0.986344</td>\n",
       "      <td>0.984994</td>\n",
       "      <td>0.985621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.299642</td>\n",
       "      <td>0.907734</td>\n",
       "      <td>0.894799</td>\n",
       "      <td>0.882516</td>\n",
       "      <td>0.886853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.075281</td>\n",
       "      <td>0.989396</td>\n",
       "      <td>0.988131</td>\n",
       "      <td>0.986228</td>\n",
       "      <td>0.987133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.297806</td>\n",
       "      <td>0.909769</td>\n",
       "      <td>0.896734</td>\n",
       "      <td>0.883925</td>\n",
       "      <td>0.888506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.070799</td>\n",
       "      <td>0.990159</td>\n",
       "      <td>0.988736</td>\n",
       "      <td>0.987294</td>\n",
       "      <td>0.987978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.296732</td>\n",
       "      <td>0.909769</td>\n",
       "      <td>0.896724</td>\n",
       "      <td>0.883925</td>\n",
       "      <td>0.888511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.067171</td>\n",
       "      <td>0.991432</td>\n",
       "      <td>0.990148</td>\n",
       "      <td>0.988937</td>\n",
       "      <td>0.989511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.296290</td>\n",
       "      <td>0.909769</td>\n",
       "      <td>0.897390</td>\n",
       "      <td>0.884608</td>\n",
       "      <td>0.889309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.070100</td>\n",
       "      <td>0.064394</td>\n",
       "      <td>0.992111</td>\n",
       "      <td>0.990837</td>\n",
       "      <td>0.990232</td>\n",
       "      <td>0.990495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.295692</td>\n",
       "      <td>0.909769</td>\n",
       "      <td>0.897381</td>\n",
       "      <td>0.884550</td>\n",
       "      <td>0.889210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.066700</td>\n",
       "      <td>0.062219</td>\n",
       "      <td>0.992365</td>\n",
       "      <td>0.991508</td>\n",
       "      <td>0.990497</td>\n",
       "      <td>0.990967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.295381</td>\n",
       "      <td>0.910448</td>\n",
       "      <td>0.897515</td>\n",
       "      <td>0.885444</td>\n",
       "      <td>0.889791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.063800</td>\n",
       "      <td>0.060736</td>\n",
       "      <td>0.992535</td>\n",
       "      <td>0.991668</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.991311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.295086</td>\n",
       "      <td>0.911126</td>\n",
       "      <td>0.898276</td>\n",
       "      <td>0.887276</td>\n",
       "      <td>0.891182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.059813</td>\n",
       "      <td>0.992620</td>\n",
       "      <td>0.991692</td>\n",
       "      <td>0.991059</td>\n",
       "      <td>0.991344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.295017</td>\n",
       "      <td>0.911805</td>\n",
       "      <td>0.899160</td>\n",
       "      <td>0.888112</td>\n",
       "      <td>0.892033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.060400</td>\n",
       "      <td>0.059507</td>\n",
       "      <td>0.992535</td>\n",
       "      <td>0.991607</td>\n",
       "      <td>0.991017</td>\n",
       "      <td>0.991281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.294952</td>\n",
       "      <td>0.911805</td>\n",
       "      <td>0.898513</td>\n",
       "      <td>0.887487</td>\n",
       "      <td>0.891408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3936' max='3936' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3936/3936 36:14, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.294905</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.901617</td>\n",
       "      <td>0.896011</td>\n",
       "      <td>0.896913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.057200</td>\n",
       "      <td>0.017390</td>\n",
       "      <td>0.998812</td>\n",
       "      <td>0.998665</td>\n",
       "      <td>0.998594</td>\n",
       "      <td>0.998627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.296570</td>\n",
       "      <td>0.912483</td>\n",
       "      <td>0.902200</td>\n",
       "      <td>0.888143</td>\n",
       "      <td>0.893473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.028900</td>\n",
       "      <td>0.010884</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999535</td>\n",
       "      <td>0.999496</td>\n",
       "      <td>0.999515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.301447</td>\n",
       "      <td>0.911805</td>\n",
       "      <td>0.898913</td>\n",
       "      <td>0.892062</td>\n",
       "      <td>0.893593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.007178</td>\n",
       "      <td>0.999746</td>\n",
       "      <td>0.999732</td>\n",
       "      <td>0.999740</td>\n",
       "      <td>0.999736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.308319</td>\n",
       "      <td>0.913161</td>\n",
       "      <td>0.902422</td>\n",
       "      <td>0.890861</td>\n",
       "      <td>0.894818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.005074</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.313674</td>\n",
       "      <td>0.911126</td>\n",
       "      <td>0.898890</td>\n",
       "      <td>0.891193</td>\n",
       "      <td>0.893213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.320387</td>\n",
       "      <td>0.911126</td>\n",
       "      <td>0.899301</td>\n",
       "      <td>0.889572</td>\n",
       "      <td>0.892535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.002995</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.325085</td>\n",
       "      <td>0.911805</td>\n",
       "      <td>0.898243</td>\n",
       "      <td>0.891092</td>\n",
       "      <td>0.893041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.328827</td>\n",
       "      <td>0.913161</td>\n",
       "      <td>0.900999</td>\n",
       "      <td>0.893134</td>\n",
       "      <td>0.895350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.002168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.332095</td>\n",
       "      <td>0.913161</td>\n",
       "      <td>0.900999</td>\n",
       "      <td>0.893134</td>\n",
       "      <td>0.895350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.334521</td>\n",
       "      <td>0.913161</td>\n",
       "      <td>0.901217</td>\n",
       "      <td>0.893134</td>\n",
       "      <td>0.895492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.001815</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.336155</td>\n",
       "      <td>0.913161</td>\n",
       "      <td>0.901217</td>\n",
       "      <td>0.893134</td>\n",
       "      <td>0.895492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.001770</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.336767</td>\n",
       "      <td>0.913161</td>\n",
       "      <td>0.900999</td>\n",
       "      <td>0.893134</td>\n",
       "      <td>0.895350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None)\n",
      "  warnings.warn(\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='954' max='954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [954/954 19:15, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.311953</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.904157</td>\n",
       "      <td>0.894242</td>\n",
       "      <td>0.896965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.004108</td>\n",
       "      <td>0.999915</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.999974</td>\n",
       "      <td>0.999966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.316609</td>\n",
       "      <td>0.911805</td>\n",
       "      <td>0.900098</td>\n",
       "      <td>0.888285</td>\n",
       "      <td>0.892644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.008500</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.324784</td>\n",
       "      <td>0.913840</td>\n",
       "      <td>0.903587</td>\n",
       "      <td>0.891740</td>\n",
       "      <td>0.895764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.001641</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.331692</td>\n",
       "      <td>0.913161</td>\n",
       "      <td>0.900408</td>\n",
       "      <td>0.891158</td>\n",
       "      <td>0.894065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.336149</td>\n",
       "      <td>0.913840</td>\n",
       "      <td>0.899218</td>\n",
       "      <td>0.891577</td>\n",
       "      <td>0.894078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.340664</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.899761</td>\n",
       "      <td>0.891639</td>\n",
       "      <td>0.894251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.000968</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.343782</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.899761</td>\n",
       "      <td>0.891639</td>\n",
       "      <td>0.894251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.000902</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.345449</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.899761</td>\n",
       "      <td>0.891639</td>\n",
       "      <td>0.894251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000880</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.346145</td>\n",
       "      <td>0.914518</td>\n",
       "      <td>0.899761</td>\n",
       "      <td>0.891639</td>\n",
       "      <td>0.894251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters:  {'learning_rate': 7.535384509295548e-05, 'num_train_epochs': 9, 'per_device_train_batch_size': 28, 'weight_decay': 0.0001717762111233837}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 147\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Hyperparameters: \u001b[39m\u001b[38;5;124m'\u001b[39m, best_hyperparameters)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;66;03m# Use the best hyperparameters for final training\u001b[39;00m\n\u001b[0;32m--> 147\u001b[0m args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m    148\u001b[0m     save_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    149\u001b[0m     evaluation_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    150\u001b[0m     load_best_model_at_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    151\u001b[0m     metric_for_best_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_macro_f1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    152\u001b[0m     logging_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    153\u001b[0m     remove_unused_columns\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    154\u001b[0m     logging_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mbest_hyperparameters  \u001b[38;5;66;03m# Use the best hyperparameters found during tuning\u001b[39;00m\n\u001b[1;32m    156\u001b[0m )\n\u001b[1;32m    158\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m    159\u001b[0m     model,\n\u001b[1;32m    160\u001b[0m     args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mprocessor\n\u001b[1;32m    166\u001b[0m )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# Add custom callback class to trainer object\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: TrainingArguments.__init__() missing 1 required positional argument: 'output_dir'"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, TrainerCallback\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform, randint, loguniform\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "import numpy as np\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "\n",
    "# Define hyperparameter distributions\n",
    "hyperparameter_distributions = {\n",
    "    \"learning_rate\": loguniform(1e-6, 1e-4),\n",
    "    \"num_train_epochs\": randint(8, 15),\n",
    "    \"per_device_train_batch_size\": randint(8, 64),\n",
    "    \"weight_decay\": loguniform(1e-5, 1e-3)\n",
    "}\n",
    "\n",
    "\n",
    "# Define batching function\n",
    "def collate_fn(examples):\n",
    "    pixels = torch.stack([example[\"pixels\"] for example in examples])\n",
    "    labels = torch.tensor([example[\"label\"] for example in examples])\n",
    "    return {\"pixel_values\": pixels, \"labels\": labels}\n",
    "\n",
    "\n",
    "# Define metrics to track, val metrics will start with \"eval_\"\n",
    "def compute_metrics(eval_pred):\n",
    "    logits = eval_pred.predictions\n",
    "    labels = eval_pred.label_ids\n",
    "\n",
    "    # Calculate Metrics\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, logits.argmax(-1), average='macro', zero_division=0)\n",
    "    acc = accuracy_score(labels, logits.argmax(-1))\n",
    "\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'macro_f1': f1\n",
    "    }\n",
    "\n",
    "# # Define custom callback function to calculate metrics for both train and val\n",
    "# class CustomCallback(TrainerCallback):\n",
    "\n",
    "#     def __init__(self, trainer) -> None:\n",
    "#         super().__init__()\n",
    "#         self._trainer = trainer\n",
    "\n",
    "#     def on_epoch_end(self, args, state, control, **kwargs):\n",
    "#         if control.should_evaluate:\n",
    "#             control_copy = deepcopy(control)\n",
    "#             self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "#             return control_copy\n",
    "\n",
    "# from transformers import TrainerCallback\n",
    "# from copy import deepcopy\n",
    "\n",
    "# # Define custom callback function that calculates metrics for both train and val and implements early stopping\n",
    "# Below custom class is from these two articles:\n",
    "# https://stackoverflow.com/questions/67457480/how-to-get-the-accuracy-per-epoch-or-step-for-the-huggingface-transformers-train\n",
    "\n",
    "# Define custom callback for early stopping and metric tracking\n",
    "class CustomCallback(TrainerCallback):\n",
    "    def __init__(self, trainer, early_stopping_patience=3, metric_name=\"eval_loss\") -> None:\n",
    "        super().__init__()\n",
    "        self._trainer = trainer\n",
    "        self.early_stopping_patience = early_stopping_patience\n",
    "        self.metric_name = metric_name\n",
    "        self.best_metric = float(\"inf\") if \"loss\" in metric_name else float(\"-inf\")\n",
    "        self.counter = 0\n",
    "\n",
    "    def on_epoch_end(self, args, state, control, **kwargs):\n",
    "        if control.should_evaluate:\n",
    "            control_copy = deepcopy(control)\n",
    "            if state.log_history:\n",
    "                eval_metrics = [log.get(self.metric_name) for log in state.log_history if log.get(self.metric_name) is not None]\n",
    "                eval_metric = max(eval_metrics) if \"loss\" in self.metric_name else min(eval_metrics)\n",
    "            else:\n",
    "                eval_metric = None\n",
    "\n",
    "            if eval_metric is None:\n",
    "                return control_copy\n",
    "\n",
    "            if (\n",
    "                (self.metric_name != \"eval_loss\" and eval_metric > self.best_metric)\n",
    "                or (self.metric_name == \"eval_loss\" and eval_metric < self.best_metric)\n",
    "            ):\n",
    "                self.counter += 1\n",
    "                if self.counter >= self.early_stopping_patience:\n",
    "                    control.should_training_stop = True\n",
    "            else:\n",
    "                self.best_metric = eval_metric\n",
    "                self.counter = 0\n",
    "\n",
    "            self._trainer.evaluate(eval_dataset=self._trainer.train_dataset, metric_key_prefix=\"train\")\n",
    "            return control_copy\n",
    "\n",
    "# Initialize best metric and best hyperparameters\n",
    "best_metric = float(\"-inf\")\n",
    "best_hyperparameters = None\n",
    "\n",
    "# Perform hyperparameter search\n",
    "param_list = list(ParameterSampler(hyperparameter_distributions, n_iter=5, random_state=42))\n",
    "for params in param_list:\n",
    "    args = TrainingArguments(\n",
    "        f\"test-trashnet\",\n",
    "        save_strategy=\"epoch\",\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"eval_macro_f1\",\n",
    "        logging_dir='logs',\n",
    "        remove_unused_columns=False,\n",
    "        logging_strategy=\"epoch\",\n",
    "        **params\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model,\n",
    "        args,\n",
    "        train_dataset=trainds,\n",
    "        eval_dataset=valds,\n",
    "        data_collator=collate_fn,\n",
    "        compute_metrics=compute_metrics,\n",
    "        tokenizer=processor\n",
    "    )\n",
    "\n",
    "    # Add custom callback class to trainer object\n",
    "    trainer.add_callback(CustomCallback(trainer, early_stopping_patience=0.5, metric_name=\"eval_macro_f1\"))\n",
    "\n",
    "    # Train the model\n",
    "    train_result = trainer.train()\n",
    "\n",
    "    # Evaluate model on validation set\n",
    "    val_predictions = trainer.predict(valds)\n",
    "    val_metrics = compute_metrics(val_predictions)\n",
    "\n",
    "    # Assuming you want to use macro F1 score for selecting the best hyperparameters\n",
    "    val_metric = val_metrics['macro_f1']\n",
    "\n",
    "    # Check if this set of hyperparameters gives better performance\n",
    "    if val_metric > best_metric:\n",
    "        best_metric = val_metric\n",
    "        best_hyperparameters = params\n",
    "\n",
    "print('Best Hyperparameters: ', best_hyperparameters)\n",
    "\n",
    "# Use the best hyperparameters for final training\n",
    "args = TrainingArguments(\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_macro_f1\",\n",
    "    logging_dir='logs',\n",
    "    remove_unused_columns=False,\n",
    "    logging_strategy=\"epoch\",\n",
    "    **best_hyperparameters  # Use the best hyperparameters found during tuning\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=trainds,\n",
    "    eval_dataset=valds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor\n",
    ")\n",
    "\n",
    "\n",
    "# Add custom callback class to trainer object\n",
    "trainer.add_callback(CustomCallback(trainer, early_stopping_patience=0.5, metric_name=\"eval_macro_f1\")) # try with eval_macro_f1 next time instead of eval_loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the best hyperparameters for final training\n",
    "args = TrainingArguments(\n",
    "    output_dir='./best_hyperparameters',\n",
    "    save_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_macro_f1\",\n",
    "    logging_dir='logs',\n",
    "    remove_unused_columns=False,\n",
    "    logging_strategy=\"epoch\",\n",
    "    **best_hyperparameters  # Use the best hyperparameters found during tuning\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=trainds,\n",
    "    eval_dataset=valds,\n",
    "    data_collator=collate_fn,\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=processor\n",
    ")\n",
    "\n",
    "\n",
    "# Add custom callback class to trainer object\n",
    "trainer.add_callback(CustomCallback(trainer, early_stopping_patience=0.5, metric_name=\"eval_macro_f1\")) # try with eval_macro_f1 next time instead of eval_loss?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3MtYdUJBt-6i",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='954' max='954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [954/954 19:15, Epoch 9/9]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Macro F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.338775</td>\n",
       "      <td>0.917232</td>\n",
       "      <td>0.908041</td>\n",
       "      <td>0.898102</td>\n",
       "      <td>0.900975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.002090</td>\n",
       "      <td>0.999491</td>\n",
       "      <td>0.999423</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.999334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.343266</td>\n",
       "      <td>0.918589</td>\n",
       "      <td>0.904352</td>\n",
       "      <td>0.899809</td>\n",
       "      <td>0.900834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.000605</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.348889</td>\n",
       "      <td>0.916554</td>\n",
       "      <td>0.904249</td>\n",
       "      <td>0.896084</td>\n",
       "      <td>0.898910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.355250</td>\n",
       "      <td>0.917232</td>\n",
       "      <td>0.905898</td>\n",
       "      <td>0.896295</td>\n",
       "      <td>0.899858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.359666</td>\n",
       "      <td>0.915875</td>\n",
       "      <td>0.904928</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.898658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000330</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.363604</td>\n",
       "      <td>0.915875</td>\n",
       "      <td>0.904928</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.898658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.366475</td>\n",
       "      <td>0.915875</td>\n",
       "      <td>0.904928</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.898658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.368072</td>\n",
       "      <td>0.915875</td>\n",
       "      <td>0.904928</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.898658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.368630</td>\n",
       "      <td>0.915875</td>\n",
       "      <td>0.904928</td>\n",
       "      <td>0.895044</td>\n",
       "      <td>0.898658</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.3387751281261444, 'test_accuracy': 0.9172320217096337, 'test_precision': 0.9080409471078748, 'test_recall': 0.898101803749702, 'test_macro_f1': 0.9009754267389722, 'test_runtime': 9.2198, 'test_samples_per_second': 159.874, 'test_steps_per_second': 5.098}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.11/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test_loss': 0.4234599173069, 'test_accuracy': 0.9043419267299865, 'test_precision': 0.8960533003481312, 'test_recall': 0.87265410674302, 'test_macro_f1': 0.8818175526988983, 'test_runtime': 9.3811, 'test_samples_per_second': 157.125, 'test_steps_per_second': 5.01}\n"
     ]
    }
   ],
   "source": [
    "train_result = trainer.train() # bottom half frozen - with test to stop after 1.0 epochs to see if early stopping works\n",
    "\n",
    "# Save the state dictionary of the ViT model\n",
    "torch.save(trainer.model, 'vit_model.pth')\n",
    "torch.save(trainer.model.state_dict, 'vit_state_dict.pth')\n",
    "\n",
    "val_performance = trainer.predict(valds)\n",
    "val_vit_predictions = val_performance.predictions.argmax(axis=1)\n",
    "print(val_performance.metrics)\n",
    "\n",
    "test_performance = trainer.predict(testds)\n",
    "test_vit_predictions = test_performance.predictions.argmax(axis=1)\n",
    "print(test_performance.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDgaBBmcuLD7"
   },
   "source": [
    "## Transfer Learning Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tFE44i6AuM6u",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train done in 204.97s\n",
      "y_train done in 0.16s\n",
      "X_val done in 23.43s\n",
      "y_val done in 0.15s\n",
      "X_test done in 23.01s\n",
      "X_yest done in 0.20s\n"
     ]
    }
   ],
   "source": [
    "# Download image arrays from S3\n",
    "start_time = time.time()\n",
    "X_train = download_from_s3(s3_bucket_name, \"rgb_npy/train/rgb_224x224_train.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "end_time = time.time()\n",
    "print(f\"X_train done in {end_time - start_time:.2f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "y_train = download_from_s3(s3_bucket_name, \"rgb_npy/train/rgb_labels_train.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "end_time = time.time()\n",
    "print(f\"y_train done in {end_time - start_time:.2f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "X_val = download_from_s3(s3_bucket_name, \"rgb_npy/val/rgb_224x224_val.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "end_time = time.time()\n",
    "print(f\"X_val done in {end_time - start_time:.2f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "y_val = download_from_s3(s3_bucket_name, \"rgb_npy/val/rgb_labels_val.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "end_time = time.time()\n",
    "print(f\"y_val done in {end_time - start_time:.2f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "X_test = download_from_s3(s3_bucket_name, \"rgb_npy/test/rgb_224x224_test.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "end_time = time.time()\n",
    "print(f\"X_test done in {end_time - start_time:.2f}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "y_test = download_from_s3(s3_bucket_name, \"rgb_npy/test/rgb_labels_test.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "end_time = time.time()\n",
    "print(f\"X_yest done in {end_time - start_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "inPTsSP9uQtt",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of classes in train: 26\n",
      "Train labels:  ['battery' 'beverage cans' 'cardboard' 'cigarette butt'\n",
      " 'construction scrap' 'electrical cables' 'electronic chips' 'glass'\n",
      " 'gloves' 'laptops' 'masks' 'medicines' 'metal containers' 'news paper'\n",
      " 'paper' 'paper_cups' 'plastic bags' 'plastic bottles'\n",
      " 'plastic containers' 'plastic_cups' 'small appliances' 'smartphones'\n",
      " 'spray cans' 'syringe' 'tetra pak' 'trash']\n",
      "Total number of classes in val: 26\n",
      "Val labels:  ['battery' 'beverage cans' 'cardboard' 'cigarette butt'\n",
      " 'construction scrap' 'electrical cables' 'electronic chips' 'glass'\n",
      " 'gloves' 'laptops' 'masks' 'medicines' 'metal containers' 'news paper'\n",
      " 'paper' 'paper_cups' 'plastic bags' 'plastic bottles'\n",
      " 'plastic containers' 'plastic_cups' 'small appliances' 'smartphones'\n",
      " 'spray cans' 'syringe' 'tetra pak' 'trash']\n"
     ]
    }
   ],
   "source": [
    "label_names = np.unique(y_train)\n",
    "print(\"Total number of classes in train:\", len(label_names))\n",
    "print(\"Train labels: \", label_names)\n",
    "\n",
    "label_names = np.unique(y_val)\n",
    "print(\"Total number of classes in val:\", len(label_names))\n",
    "print(\"Val labels: \", label_names)\n",
    "\n",
    "# String index labels for tensorflow\n",
    "y_train = np.unique(y_train, return_inverse=True)[1]\n",
    "y_val = np.unique(y_val, return_inverse=True)[1]\n",
    "y_test = np.unique(y_test, return_inverse=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Hyfh8JOTun8H",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training resnet18...\n",
      "Epoch 1/8, Train Loss: 2.8182, Train Accuracy: 21.14%, Train F1: 0.0868\n",
      "Epoch 2/8, Train Loss: 2.5007, Train Accuracy: 26.94%, Train F1: 0.1471\n",
      "Epoch 3/8, Train Loss: 2.3530, Train Accuracy: 32.89%, Train F1: 0.1855\n",
      "Epoch 4/8, Train Loss: 2.2027, Train Accuracy: 37.35%, Train F1: 0.2262\n",
      "Epoch 5/8, Train Loss: 2.0610, Train Accuracy: 41.02%, Train F1: 0.2787\n",
      "Epoch 6/8, Train Loss: 1.9125, Train Accuracy: 44.42%, Train F1: 0.3292\n",
      "Epoch 7/8, Train Loss: 1.7742, Train Accuracy: 48.42%, Train F1: 0.3763\n",
      "Epoch 8/8, Train Loss: 1.6462, Train Accuracy: 51.31%, Train F1: 0.4093\n",
      "Validation Loss: 1.8761, Accuracy: 48.30%, F1: 0.3567 with params: {'weight_decay': 1e-06, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.4767, Train Accuracy: 31.34%, Train F1: 0.1525\n",
      "Epoch 2/10, Train Loss: 2.0384, Train Accuracy: 40.91%, Train F1: 0.2802\n",
      "Epoch 3/10, Train Loss: 1.8412, Train Accuracy: 46.03%, Train F1: 0.3335\n",
      "Epoch 4/10, Train Loss: 1.6905, Train Accuracy: 50.73%, Train F1: 0.3892\n",
      "Epoch 5/10, Train Loss: 1.5458, Train Accuracy: 54.13%, Train F1: 0.4331\n",
      "Epoch 6/10, Train Loss: 1.4307, Train Accuracy: 57.77%, Train F1: 0.4803\n",
      "Epoch 7/10, Train Loss: 1.3012, Train Accuracy: 61.11%, Train F1: 0.5182\n",
      "Epoch 8/10, Train Loss: 1.2030, Train Accuracy: 63.96%, Train F1: 0.5575\n",
      "Epoch 9/10, Train Loss: 1.0993, Train Accuracy: 66.64%, Train F1: 0.5885\n",
      "Epoch 10/10, Train Loss: 1.0028, Train Accuracy: 69.70%, Train F1: 0.6262\n",
      "Validation Loss: 1.4451, Accuracy: 57.53%, F1: 0.4701 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/8, Train Loss: 2.8412, Train Accuracy: 20.55%, Train F1: 0.0709\n",
      "Epoch 2/8, Train Loss: 2.5039, Train Accuracy: 27.98%, Train F1: 0.1456\n",
      "Epoch 3/8, Train Loss: 2.3414, Train Accuracy: 33.54%, Train F1: 0.1915\n",
      "Epoch 4/8, Train Loss: 2.1864, Train Accuracy: 37.22%, Train F1: 0.2349\n",
      "Epoch 5/8, Train Loss: 2.0476, Train Accuracy: 40.46%, Train F1: 0.2739\n",
      "Epoch 6/8, Train Loss: 1.9230, Train Accuracy: 44.14%, Train F1: 0.3202\n",
      "Epoch 7/8, Train Loss: 1.8032, Train Accuracy: 47.62%, Train F1: 0.3581\n",
      "Epoch 8/8, Train Loss: 1.6888, Train Accuracy: 50.58%, Train F1: 0.3947\n",
      "Validation Loss: 2.0967, Accuracy: 39.01%, F1: 0.2717 with params: {'weight_decay': 1e-05, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 2.4768, Train Accuracy: 31.40%, Train F1: 0.1411\n",
      "Epoch 2/10, Train Loss: 2.0898, Train Accuracy: 39.79%, Train F1: 0.2740\n",
      "Epoch 3/10, Train Loss: 1.8857, Train Accuracy: 44.77%, Train F1: 0.3271\n",
      "Epoch 4/10, Train Loss: 1.7246, Train Accuracy: 49.13%, Train F1: 0.3791\n",
      "Epoch 5/10, Train Loss: 1.5758, Train Accuracy: 53.32%, Train F1: 0.4296\n",
      "Epoch 6/10, Train Loss: 1.4467, Train Accuracy: 57.02%, Train F1: 0.4726\n",
      "Epoch 7/10, Train Loss: 1.3288, Train Accuracy: 60.47%, Train F1: 0.5131\n",
      "Epoch 8/10, Train Loss: 1.2102, Train Accuracy: 63.58%, Train F1: 0.5492\n",
      "Epoch 9/10, Train Loss: 1.0813, Train Accuracy: 67.24%, Train F1: 0.5975\n",
      "Epoch 10/10, Train Loss: 0.9728, Train Accuracy: 70.33%, Train F1: 0.6351\n",
      "Validation Loss: 1.3668, Accuracy: 62.08%, F1: 0.5216 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/12, Train Loss: 3.1692, Train Accuracy: 18.55%, Train F1: 0.0670\n",
      "Epoch 2/12, Train Loss: 2.5684, Train Accuracy: 26.75%, Train F1: 0.1296\n",
      "Epoch 3/12, Train Loss: 2.4429, Train Accuracy: 30.45%, Train F1: 0.1563\n",
      "Epoch 4/12, Train Loss: 2.3352, Train Accuracy: 33.69%, Train F1: 0.1827\n",
      "Epoch 5/12, Train Loss: 2.2611, Train Accuracy: 36.14%, Train F1: 0.2096\n",
      "Epoch 6/12, Train Loss: 2.1921, Train Accuracy: 36.86%, Train F1: 0.2259\n",
      "Epoch 7/12, Train Loss: 2.1220, Train Accuracy: 38.83%, Train F1: 0.2411\n",
      "Epoch 8/12, Train Loss: 2.0826, Train Accuracy: 39.79%, Train F1: 0.2607\n",
      "Epoch 9/12, Train Loss: 2.0426, Train Accuracy: 40.94%, Train F1: 0.2697\n",
      "Epoch 10/12, Train Loss: 1.9985, Train Accuracy: 41.99%, Train F1: 0.2776\n",
      "Epoch 11/12, Train Loss: 1.9571, Train Accuracy: 43.25%, Train F1: 0.2941\n",
      "Epoch 12/12, Train Loss: 1.9182, Train Accuracy: 44.08%, Train F1: 0.3046\n",
      "Validation Loss: 2.0814, Accuracy: 40.77%, F1: 0.2697 with params: {'weight_decay': 1e-06, 'learning_rate': 0.1, 'epochs': 12, 'batch_size': 64}\n",
      "Best validation F1 score: 0.5216 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.5037, Train Accuracy: 30.83%, Train F1: 0.1471\n",
      "Epoch 2/10, Train Loss: 2.0814, Train Accuracy: 39.58%, Train F1: 0.2609\n",
      "Epoch 3/10, Train Loss: 1.8688, Train Accuracy: 45.41%, Train F1: 0.3257\n",
      "Epoch 4/10, Train Loss: 1.6948, Train Accuracy: 50.00%, Train F1: 0.3881\n",
      "Epoch 5/10, Train Loss: 1.5670, Train Accuracy: 53.88%, Train F1: 0.4362\n",
      "Epoch 6/10, Train Loss: 1.4363, Train Accuracy: 57.36%, Train F1: 0.4723\n",
      "Epoch 7/10, Train Loss: 1.2920, Train Accuracy: 61.03%, Train F1: 0.5189\n",
      "Epoch 8/10, Train Loss: 1.1954, Train Accuracy: 64.31%, Train F1: 0.5631\n",
      "Epoch 9/10, Train Loss: 1.0781, Train Accuracy: 67.32%, Train F1: 0.5968\n",
      "Epoch 10/10, Train Loss: 0.9653, Train Accuracy: 70.51%, Train F1: 0.6369\n",
      "Final Validation Loss: 1.4980, Accuracy: 55.97%, F1: 0.4659\n",
      "Training resnet50...\n",
      "Epoch 1/8, Train Loss: 3.2442, Train Accuracy: 16.67%, Train F1: 0.0513\n",
      "Epoch 2/8, Train Loss: 2.6215, Train Accuracy: 23.79%, Train F1: 0.1137\n",
      "Epoch 3/8, Train Loss: 2.4373, Train Accuracy: 29.77%, Train F1: 0.1641\n",
      "Epoch 4/8, Train Loss: 2.4253, Train Accuracy: 29.00%, Train F1: 0.1739\n",
      "Epoch 5/8, Train Loss: 2.2063, Train Accuracy: 36.36%, Train F1: 0.2339\n",
      "Epoch 6/8, Train Loss: 2.0817, Train Accuracy: 39.82%, Train F1: 0.2653\n",
      "Epoch 7/8, Train Loss: 1.9623, Train Accuracy: 43.03%, Train F1: 0.3072\n",
      "Epoch 8/8, Train Loss: 1.8677, Train Accuracy: 45.40%, Train F1: 0.3382\n",
      "Validation Loss: 4.5155, Accuracy: 22.66%, F1: 0.1606 with params: {'weight_decay': 1e-06, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.6351, Train Accuracy: 27.94%, Train F1: 0.1351\n",
      "Epoch 2/10, Train Loss: 2.1937, Train Accuracy: 37.34%, Train F1: 0.2350\n",
      "Epoch 3/10, Train Loss: 1.9914, Train Accuracy: 42.60%, Train F1: 0.2934\n",
      "Epoch 4/10, Train Loss: 1.8045, Train Accuracy: 47.54%, Train F1: 0.3459\n",
      "Epoch 5/10, Train Loss: 1.6727, Train Accuracy: 50.86%, Train F1: 0.3909\n",
      "Epoch 6/10, Train Loss: 1.5509, Train Accuracy: 54.63%, Train F1: 0.4320\n",
      "Epoch 7/10, Train Loss: 1.4567, Train Accuracy: 56.71%, Train F1: 0.4639\n",
      "Epoch 8/10, Train Loss: 1.3653, Train Accuracy: 59.20%, Train F1: 0.4979\n",
      "Epoch 9/10, Train Loss: 1.2857, Train Accuracy: 61.42%, Train F1: 0.5224\n",
      "Epoch 10/10, Train Loss: 1.1732, Train Accuracy: 65.05%, Train F1: 0.5679\n",
      "Validation Loss: 1.6265, Accuracy: 53.93%, F1: 0.4256 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/8, Train Loss: 3.1767, Train Accuracy: 18.18%, Train F1: 0.0625\n",
      "Epoch 2/8, Train Loss: 2.6317, Train Accuracy: 24.38%, Train F1: 0.1184\n",
      "Epoch 3/8, Train Loss: 2.4925, Train Accuracy: 28.76%, Train F1: 0.1422\n",
      "Epoch 4/8, Train Loss: 2.3794, Train Accuracy: 32.53%, Train F1: 0.1809\n",
      "Epoch 5/8, Train Loss: 2.2283, Train Accuracy: 36.01%, Train F1: 0.2192\n",
      "Epoch 6/8, Train Loss: 2.1060, Train Accuracy: 39.99%, Train F1: 0.2673\n",
      "Epoch 7/8, Train Loss: 1.9899, Train Accuracy: 42.54%, Train F1: 0.2937\n",
      "Epoch 8/8, Train Loss: 1.8875, Train Accuracy: 44.85%, Train F1: 0.3234\n",
      "Validation Loss: 1.9344, Accuracy: 45.66%, F1: 0.3295 with params: {'weight_decay': 1e-05, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 2.7069, Train Accuracy: 26.76%, Train F1: 0.1216\n",
      "Epoch 2/10, Train Loss: 2.3243, Train Accuracy: 34.56%, Train F1: 0.2033\n",
      "Epoch 3/10, Train Loss: 2.0572, Train Accuracy: 41.20%, Train F1: 0.2704\n",
      "Epoch 4/10, Train Loss: 1.9059, Train Accuracy: 44.72%, Train F1: 0.3173\n",
      "Epoch 5/10, Train Loss: 1.7430, Train Accuracy: 49.27%, Train F1: 0.3751\n",
      "Epoch 6/10, Train Loss: 1.5854, Train Accuracy: 53.57%, Train F1: 0.4253\n",
      "Epoch 7/10, Train Loss: 1.5246, Train Accuracy: 55.23%, Train F1: 0.4447\n",
      "Epoch 8/10, Train Loss: 1.3877, Train Accuracy: 58.82%, Train F1: 0.4943\n",
      "Epoch 9/10, Train Loss: 1.3042, Train Accuracy: 61.05%, Train F1: 0.5211\n",
      "Epoch 10/10, Train Loss: 1.2408, Train Accuracy: 63.24%, Train F1: 0.5488\n",
      "Validation Loss: 1.7700, Accuracy: 50.00%, F1: 0.4083 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/12, Train Loss: 4.0225, Train Accuracy: 17.38%, Train F1: 0.0587\n",
      "Epoch 2/12, Train Loss: 2.8250, Train Accuracy: 19.79%, Train F1: 0.0772\n",
      "Epoch 3/12, Train Loss: 2.6586, Train Accuracy: 24.08%, Train F1: 0.0996\n",
      "Epoch 4/12, Train Loss: 2.6249, Train Accuracy: 25.03%, Train F1: 0.1089\n",
      "Epoch 5/12, Train Loss: 2.6121, Train Accuracy: 25.32%, Train F1: 0.1148\n",
      "Epoch 6/12, Train Loss: 2.6058, Train Accuracy: 25.45%, Train F1: 0.1218\n",
      "Epoch 7/12, Train Loss: 2.5274, Train Accuracy: 27.47%, Train F1: 0.1280\n",
      "Epoch 8/12, Train Loss: 2.5164, Train Accuracy: 28.03%, Train F1: 0.1313\n",
      "Epoch 9/12, Train Loss: 2.4784, Train Accuracy: 28.78%, Train F1: 0.1391\n",
      "Epoch 10/12, Train Loss: 2.4304, Train Accuracy: 30.18%, Train F1: 0.1505\n",
      "Epoch 11/12, Train Loss: 2.3937, Train Accuracy: 31.75%, Train F1: 0.1636\n",
      "Epoch 12/12, Train Loss: 2.4439, Train Accuracy: 31.79%, Train F1: 0.1661\n",
      "Validation Loss: 161.6621, Accuracy: 10.65%, F1: 0.0468 with params: {'weight_decay': 1e-06, 'learning_rate': 0.1, 'epochs': 12, 'batch_size': 64}\n",
      "Best validation F1 score: 0.4256 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 2.6880, Train Accuracy: 26.48%, Train F1: 0.1286\n",
      "Epoch 2/10, Train Loss: 2.2784, Train Accuracy: 36.04%, Train F1: 0.2214\n",
      "Epoch 3/10, Train Loss: 2.0390, Train Accuracy: 41.36%, Train F1: 0.2767\n",
      "Epoch 4/10, Train Loss: 1.8773, Train Accuracy: 45.30%, Train F1: 0.3238\n",
      "Epoch 5/10, Train Loss: 1.6917, Train Accuracy: 50.42%, Train F1: 0.3787\n",
      "Epoch 6/10, Train Loss: 1.5726, Train Accuracy: 53.80%, Train F1: 0.4242\n",
      "Epoch 7/10, Train Loss: 1.4825, Train Accuracy: 56.40%, Train F1: 0.4582\n",
      "Epoch 8/10, Train Loss: 1.4918, Train Accuracy: 56.91%, Train F1: 0.4700\n",
      "Epoch 9/10, Train Loss: 1.3536, Train Accuracy: 59.76%, Train F1: 0.5018\n",
      "Epoch 10/10, Train Loss: 1.2401, Train Accuracy: 62.67%, Train F1: 0.5397\n",
      "Final Validation Loss: 1.7463, Accuracy: 55.63%, F1: 0.4581\n",
      "Training densenet121...\n",
      "Epoch 1/8, Train Loss: 2.8864, Train Accuracy: 19.20%, Train F1: 0.0707\n",
      "Epoch 2/8, Train Loss: 2.4673, Train Accuracy: 28.44%, Train F1: 0.1523\n",
      "Epoch 3/8, Train Loss: 2.2573, Train Accuracy: 35.23%, Train F1: 0.2157\n",
      "Epoch 4/8, Train Loss: 2.0971, Train Accuracy: 39.80%, Train F1: 0.2575\n",
      "Epoch 5/8, Train Loss: 1.9242, Train Accuracy: 43.87%, Train F1: 0.3115\n",
      "Epoch 6/8, Train Loss: 1.8213, Train Accuracy: 46.71%, Train F1: 0.3457\n",
      "Epoch 7/8, Train Loss: 1.7106, Train Accuracy: 49.97%, Train F1: 0.3845\n",
      "Epoch 8/8, Train Loss: 1.5907, Train Accuracy: 53.29%, Train F1: 0.4188\n",
      "Validation Loss: 2.1581, Accuracy: 35.75%, F1: 0.2526 with params: {'weight_decay': 1e-06, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.3498, Train Accuracy: 35.94%, Train F1: 0.1275\n",
      "Epoch 2/10, Train Loss: 1.8640, Train Accuracy: 45.89%, Train F1: 0.3246\n",
      "Epoch 3/10, Train Loss: 1.6551, Train Accuracy: 51.70%, Train F1: 0.3933\n",
      "Epoch 4/10, Train Loss: 1.4729, Train Accuracy: 57.00%, Train F1: 0.4562\n",
      "Epoch 5/10, Train Loss: 1.3449, Train Accuracy: 60.33%, Train F1: 0.4991\n",
      "Epoch 6/10, Train Loss: 1.2307, Train Accuracy: 63.51%, Train F1: 0.5443\n",
      "Epoch 7/10, Train Loss: 1.1418, Train Accuracy: 65.93%, Train F1: 0.5725\n",
      "Epoch 8/10, Train Loss: 1.0602, Train Accuracy: 68.17%, Train F1: 0.5988\n",
      "Epoch 9/10, Train Loss: 0.9889, Train Accuracy: 70.17%, Train F1: 0.6263\n",
      "Epoch 10/10, Train Loss: 0.9256, Train Accuracy: 71.58%, Train F1: 0.6458\n",
      "Validation Loss: 1.3491, Accuracy: 62.69%, F1: 0.5128 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/8, Train Loss: 2.8385, Train Accuracy: 21.17%, Train F1: 0.0663\n",
      "Epoch 2/8, Train Loss: 2.4531, Train Accuracy: 29.97%, Train F1: 0.1624\n",
      "Epoch 3/8, Train Loss: 2.2721, Train Accuracy: 34.89%, Train F1: 0.2099\n",
      "Epoch 4/8, Train Loss: 2.1189, Train Accuracy: 39.43%, Train F1: 0.2613\n",
      "Epoch 5/8, Train Loss: 1.9754, Train Accuracy: 43.13%, Train F1: 0.3074\n",
      "Epoch 6/8, Train Loss: 1.8276, Train Accuracy: 46.66%, Train F1: 0.3484\n",
      "Epoch 7/8, Train Loss: 1.7299, Train Accuracy: 49.71%, Train F1: 0.3844\n",
      "Epoch 8/8, Train Loss: 1.6398, Train Accuracy: 51.71%, Train F1: 0.4054\n",
      "Validation Loss: 2.4341, Accuracy: 34.53%, F1: 0.2328 with params: {'weight_decay': 1e-05, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 2.3651, Train Accuracy: 34.24%, Train F1: 0.1205\n",
      "Epoch 2/10, Train Loss: 1.8436, Train Accuracy: 45.77%, Train F1: 0.3205\n",
      "Epoch 3/10, Train Loss: 1.6285, Train Accuracy: 51.99%, Train F1: 0.3965\n",
      "Epoch 4/10, Train Loss: 1.4511, Train Accuracy: 57.17%, Train F1: 0.4625\n",
      "Epoch 5/10, Train Loss: 1.3472, Train Accuracy: 59.98%, Train F1: 0.4948\n",
      "Epoch 6/10, Train Loss: 1.2239, Train Accuracy: 63.18%, Train F1: 0.5447\n",
      "Epoch 7/10, Train Loss: 1.1343, Train Accuracy: 65.71%, Train F1: 0.5735\n",
      "Epoch 8/10, Train Loss: 1.0327, Train Accuracy: 68.81%, Train F1: 0.6143\n",
      "Epoch 9/10, Train Loss: 0.9820, Train Accuracy: 69.80%, Train F1: 0.6277\n",
      "Epoch 10/10, Train Loss: 0.9047, Train Accuracy: 72.20%, Train F1: 0.6578\n",
      "Validation Loss: 1.4412, Accuracy: 59.29%, F1: 0.5380 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/12, Train Loss: 3.1025, Train Accuracy: 18.37%, Train F1: 0.0485\n",
      "Epoch 2/12, Train Loss: 2.5687, Train Accuracy: 26.60%, Train F1: 0.1309\n",
      "Epoch 3/12, Train Loss: 2.4132, Train Accuracy: 31.12%, Train F1: 0.1680\n",
      "Epoch 4/12, Train Loss: 2.2900, Train Accuracy: 34.63%, Train F1: 0.1938\n",
      "Epoch 5/12, Train Loss: 2.2103, Train Accuracy: 37.05%, Train F1: 0.2178\n",
      "Epoch 6/12, Train Loss: 2.1108, Train Accuracy: 39.78%, Train F1: 0.2468\n",
      "Epoch 7/12, Train Loss: 2.0235, Train Accuracy: 42.08%, Train F1: 0.2702\n",
      "Epoch 8/12, Train Loss: 1.9732, Train Accuracy: 43.61%, Train F1: 0.2909\n",
      "Epoch 9/12, Train Loss: 1.9354, Train Accuracy: 44.38%, Train F1: 0.2980\n",
      "Epoch 10/12, Train Loss: 1.8838, Train Accuracy: 45.83%, Train F1: 0.3148\n",
      "Epoch 11/12, Train Loss: 1.8410, Train Accuracy: 46.28%, Train F1: 0.3246\n",
      "Epoch 12/12, Train Loss: 1.7865, Train Accuracy: 48.25%, Train F1: 0.3442\n",
      "Validation Loss: 1.9163, Accuracy: 44.10%, F1: 0.3058 with params: {'weight_decay': 1e-06, 'learning_rate': 0.1, 'epochs': 12, 'batch_size': 64}\n",
      "Best validation F1 score: 0.5380 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.3322, Train Accuracy: 35.54%, Train F1: 0.1302\n",
      "Epoch 2/10, Train Loss: 1.8381, Train Accuracy: 47.01%, Train F1: 0.3389\n",
      "Epoch 3/10, Train Loss: 1.6378, Train Accuracy: 51.99%, Train F1: 0.3944\n",
      "Epoch 4/10, Train Loss: 1.4426, Train Accuracy: 57.07%, Train F1: 0.4689\n",
      "Epoch 5/10, Train Loss: 1.3300, Train Accuracy: 60.57%, Train F1: 0.5075\n",
      "Epoch 6/10, Train Loss: 1.2071, Train Accuracy: 64.17%, Train F1: 0.5560\n",
      "Epoch 7/10, Train Loss: 1.1097, Train Accuracy: 65.86%, Train F1: 0.5769\n",
      "Epoch 8/10, Train Loss: 1.0247, Train Accuracy: 69.27%, Train F1: 0.6153\n",
      "Epoch 9/10, Train Loss: 0.9547, Train Accuracy: 71.00%, Train F1: 0.6372\n",
      "Epoch 10/10, Train Loss: 0.9073, Train Accuracy: 72.27%, Train F1: 0.6556\n",
      "Final Validation Loss: 1.1456, Accuracy: 65.13%, F1: 0.5819\n",
      "Training mobilenet_v2...\n",
      "Epoch 1/8, Train Loss: 2.8098, Train Accuracy: 22.18%, Train F1: 0.0581\n",
      "Epoch 2/8, Train Loss: 2.4628, Train Accuracy: 30.53%, Train F1: 0.1507\n",
      "Epoch 3/8, Train Loss: 2.3127, Train Accuracy: 34.70%, Train F1: 0.1801\n",
      "Epoch 4/8, Train Loss: 2.1793, Train Accuracy: 37.45%, Train F1: 0.2096\n",
      "Epoch 5/8, Train Loss: 2.0768, Train Accuracy: 39.46%, Train F1: 0.2346\n",
      "Epoch 6/8, Train Loss: 1.9808, Train Accuracy: 42.60%, Train F1: 0.2702\n",
      "Epoch 7/8, Train Loss: 1.8707, Train Accuracy: 45.41%, Train F1: 0.3064\n",
      "Epoch 8/8, Train Loss: 1.7908, Train Accuracy: 48.50%, Train F1: 0.3383\n",
      "Validation Loss: 1.7804, Accuracy: 47.83%, F1: 0.3220 with params: {'weight_decay': 1e-06, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.5772, Train Accuracy: 29.39%, Train F1: 0.0739\n",
      "Epoch 2/10, Train Loss: 2.1025, Train Accuracy: 39.41%, Train F1: 0.2403\n",
      "Epoch 3/10, Train Loss: 1.8615, Train Accuracy: 46.10%, Train F1: 0.3153\n",
      "Epoch 4/10, Train Loss: 1.6877, Train Accuracy: 50.42%, Train F1: 0.3691\n",
      "Epoch 5/10, Train Loss: 1.5098, Train Accuracy: 54.54%, Train F1: 0.4224\n",
      "Epoch 6/10, Train Loss: 1.4204, Train Accuracy: 57.18%, Train F1: 0.4599\n",
      "Epoch 7/10, Train Loss: 1.2806, Train Accuracy: 61.22%, Train F1: 0.5117\n",
      "Epoch 8/10, Train Loss: 1.1853, Train Accuracy: 63.93%, Train F1: 0.5467\n",
      "Epoch 9/10, Train Loss: 1.0677, Train Accuracy: 67.48%, Train F1: 0.5871\n",
      "Epoch 10/10, Train Loss: 0.9975, Train Accuracy: 69.33%, Train F1: 0.6166\n",
      "Validation Loss: 1.8550, Accuracy: 50.00%, F1: 0.4366 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/8, Train Loss: 2.8010, Train Accuracy: 22.35%, Train F1: 0.0528\n",
      "Epoch 2/8, Train Loss: 2.5621, Train Accuracy: 27.36%, Train F1: 0.1388\n",
      "Epoch 3/8, Train Loss: 2.4339, Train Accuracy: 31.65%, Train F1: 0.1638\n",
      "Epoch 4/8, Train Loss: 2.3194, Train Accuracy: 34.65%, Train F1: 0.1861\n",
      "Epoch 5/8, Train Loss: 2.2423, Train Accuracy: 36.79%, Train F1: 0.2097\n",
      "Epoch 6/8, Train Loss: 2.1256, Train Accuracy: 39.47%, Train F1: 0.2378\n",
      "Epoch 7/8, Train Loss: 2.0587, Train Accuracy: 40.58%, Train F1: 0.2545\n",
      "Epoch 8/8, Train Loss: 1.9578, Train Accuracy: 43.31%, Train F1: 0.2808\n",
      "Validation Loss: 2.0261, Accuracy: 44.50%, F1: 0.2743 with params: {'weight_decay': 1e-05, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 2.5855, Train Accuracy: 28.54%, Train F1: 0.0954\n",
      "Epoch 2/10, Train Loss: 2.1042, Train Accuracy: 39.13%, Train F1: 0.2438\n",
      "Epoch 3/10, Train Loss: 1.8745, Train Accuracy: 45.71%, Train F1: 0.3111\n",
      "Epoch 4/10, Train Loss: 1.6822, Train Accuracy: 51.18%, Train F1: 0.3766\n",
      "Epoch 5/10, Train Loss: 1.5345, Train Accuracy: 54.46%, Train F1: 0.4203\n",
      "Epoch 6/10, Train Loss: 1.3789, Train Accuracy: 58.71%, Train F1: 0.4795\n",
      "Epoch 7/10, Train Loss: 1.2594, Train Accuracy: 62.15%, Train F1: 0.5203\n",
      "Epoch 8/10, Train Loss: 1.1630, Train Accuracy: 65.16%, Train F1: 0.5646\n",
      "Epoch 9/10, Train Loss: 1.0510, Train Accuracy: 68.08%, Train F1: 0.5998\n",
      "Epoch 10/10, Train Loss: 0.9451, Train Accuracy: 70.86%, Train F1: 0.6330\n",
      "Validation Loss: 1.5117, Accuracy: 59.02%, F1: 0.4898 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/12, Train Loss: 3.4142, Train Accuracy: 17.48%, Train F1: 0.0328\n",
      "Epoch 2/12, Train Loss: 2.6909, Train Accuracy: 22.85%, Train F1: 0.0969\n",
      "Epoch 3/12, Train Loss: 2.6252, Train Accuracy: 24.29%, Train F1: 0.1023\n",
      "Epoch 4/12, Train Loss: 2.5804, Train Accuracy: 25.59%, Train F1: 0.1129\n",
      "Epoch 5/12, Train Loss: 2.5505, Train Accuracy: 26.23%, Train F1: 0.1182\n",
      "Epoch 6/12, Train Loss: 2.5379, Train Accuracy: 27.94%, Train F1: 0.1283\n",
      "Epoch 7/12, Train Loss: 2.5178, Train Accuracy: 28.24%, Train F1: 0.1272\n",
      "Epoch 8/12, Train Loss: 2.4630, Train Accuracy: 30.08%, Train F1: 0.1389\n",
      "Epoch 9/12, Train Loss: 2.4288, Train Accuracy: 31.50%, Train F1: 0.1489\n",
      "Epoch 10/12, Train Loss: 2.4019, Train Accuracy: 32.24%, Train F1: 0.1457\n",
      "Epoch 11/12, Train Loss: 2.3898, Train Accuracy: 31.93%, Train F1: 0.1539\n",
      "Epoch 12/12, Train Loss: 2.3543, Train Accuracy: 33.38%, Train F1: 0.1605\n",
      "Validation Loss: 2.5900, Accuracy: 27.61%, F1: 0.0897 with params: {'weight_decay': 1e-06, 'learning_rate': 0.1, 'epochs': 12, 'batch_size': 64}\n",
      "Best validation F1 score: 0.4898 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.5865, Train Accuracy: 28.05%, Train F1: 0.0875\n",
      "Epoch 2/10, Train Loss: 2.1103, Train Accuracy: 39.26%, Train F1: 0.2410\n",
      "Epoch 3/10, Train Loss: 1.8853, Train Accuracy: 45.34%, Train F1: 0.3112\n",
      "Epoch 4/10, Train Loss: 1.6661, Train Accuracy: 51.08%, Train F1: 0.3819\n",
      "Epoch 5/10, Train Loss: 1.4986, Train Accuracy: 55.59%, Train F1: 0.4386\n",
      "Epoch 6/10, Train Loss: 1.3415, Train Accuracy: 59.73%, Train F1: 0.4945\n",
      "Epoch 7/10, Train Loss: 1.2411, Train Accuracy: 62.57%, Train F1: 0.5284\n",
      "Epoch 8/10, Train Loss: 1.1301, Train Accuracy: 65.81%, Train F1: 0.5731\n",
      "Epoch 9/10, Train Loss: 1.0142, Train Accuracy: 69.14%, Train F1: 0.6173\n",
      "Epoch 10/10, Train Loss: 0.9419, Train Accuracy: 71.39%, Train F1: 0.6389\n",
      "Final Validation Loss: 1.4718, Accuracy: 60.11%, F1: 0.5205\n",
      "Training resnet101...\n",
      "Epoch 1/8, Train Loss: 3.1452, Train Accuracy: 14.93%, Train F1: 0.0404\n",
      "Epoch 2/8, Train Loss: 2.7279, Train Accuracy: 20.89%, Train F1: 0.0917\n",
      "Epoch 3/8, Train Loss: 2.6035, Train Accuracy: 24.76%, Train F1: 0.1160\n",
      "Epoch 4/8, Train Loss: 2.4848, Train Accuracy: 28.33%, Train F1: 0.1462\n",
      "Epoch 5/8, Train Loss: 2.3728, Train Accuracy: 31.46%, Train F1: 0.1748\n",
      "Epoch 6/8, Train Loss: 2.2816, Train Accuracy: 34.10%, Train F1: 0.1965\n",
      "Epoch 7/8, Train Loss: 2.1958, Train Accuracy: 37.50%, Train F1: 0.2257\n",
      "Epoch 8/8, Train Loss: 2.1019, Train Accuracy: 39.40%, Train F1: 0.2559\n",
      "Validation Loss: 2.4398, Accuracy: 35.96%, F1: 0.1926 with params: {'weight_decay': 1e-06, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.7708, Train Accuracy: 23.60%, Train F1: 0.1116\n",
      "Epoch 2/10, Train Loss: 2.3798, Train Accuracy: 32.97%, Train F1: 0.1809\n",
      "Epoch 3/10, Train Loss: 2.1943, Train Accuracy: 37.51%, Train F1: 0.2238\n",
      "Epoch 4/10, Train Loss: 2.0429, Train Accuracy: 41.81%, Train F1: 0.2708\n",
      "Epoch 5/10, Train Loss: 1.9027, Train Accuracy: 44.81%, Train F1: 0.3114\n",
      "Epoch 6/10, Train Loss: 1.7875, Train Accuracy: 47.96%, Train F1: 0.3505\n",
      "Epoch 7/10, Train Loss: 1.6569, Train Accuracy: 51.19%, Train F1: 0.3924\n",
      "Epoch 8/10, Train Loss: 1.5431, Train Accuracy: 54.84%, Train F1: 0.4410\n",
      "Epoch 9/10, Train Loss: 1.4347, Train Accuracy: 57.47%, Train F1: 0.4751\n",
      "Epoch 10/10, Train Loss: 1.3753, Train Accuracy: 59.01%, Train F1: 0.4906\n",
      "Validation Loss: 1.6789, Accuracy: 48.78%, F1: 0.3950 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/8, Train Loss: 3.2013, Train Accuracy: 15.14%, Train F1: 0.0449\n",
      "Epoch 2/8, Train Loss: 2.7227, Train Accuracy: 21.68%, Train F1: 0.0956\n",
      "Epoch 3/8, Train Loss: 2.5481, Train Accuracy: 26.96%, Train F1: 0.1345\n",
      "Epoch 4/8, Train Loss: 2.4430, Train Accuracy: 30.53%, Train F1: 0.1665\n",
      "Epoch 5/8, Train Loss: 2.3345, Train Accuracy: 33.45%, Train F1: 0.1912\n",
      "Epoch 6/8, Train Loss: 2.2240, Train Accuracy: 36.18%, Train F1: 0.2203\n",
      "Epoch 7/8, Train Loss: 2.1046, Train Accuracy: 39.90%, Train F1: 0.2602\n",
      "Epoch 8/8, Train Loss: 1.9988, Train Accuracy: 42.49%, Train F1: 0.2924\n",
      "Validation Loss: 2.3062, Accuracy: 34.06%, F1: 0.2339 with params: {'weight_decay': 1e-05, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 2.7296, Train Accuracy: 26.36%, Train F1: 0.0920\n",
      "Epoch 2/10, Train Loss: 2.3358, Train Accuracy: 34.66%, Train F1: 0.1972\n",
      "Epoch 3/10, Train Loss: 2.1720, Train Accuracy: 37.44%, Train F1: 0.2299\n",
      "Epoch 4/10, Train Loss: 1.9853, Train Accuracy: 42.64%, Train F1: 0.2936\n",
      "Epoch 5/10, Train Loss: 1.8463, Train Accuracy: 46.40%, Train F1: 0.3315\n",
      "Epoch 6/10, Train Loss: 1.7251, Train Accuracy: 49.85%, Train F1: 0.3828\n",
      "Epoch 7/10, Train Loss: 1.7352, Train Accuracy: 48.13%, Train F1: 0.3696\n",
      "Epoch 8/10, Train Loss: 1.5901, Train Accuracy: 53.20%, Train F1: 0.4277\n",
      "Epoch 9/10, Train Loss: 1.4325, Train Accuracy: 57.44%, Train F1: 0.4791\n",
      "Epoch 10/10, Train Loss: 1.3220, Train Accuracy: 60.21%, Train F1: 0.5120\n",
      "Validation Loss: 1.8152, Accuracy: 49.59%, F1: 0.3919 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/12, Train Loss: 3.9432, Train Accuracy: 12.63%, Train F1: 0.0426\n",
      "Epoch 2/12, Train Loss: 2.7932, Train Accuracy: 18.13%, Train F1: 0.0764\n",
      "Epoch 3/12, Train Loss: 2.7159, Train Accuracy: 20.44%, Train F1: 0.0923\n",
      "Epoch 4/12, Train Loss: 2.6464, Train Accuracy: 23.12%, Train F1: 0.1065\n",
      "Epoch 5/12, Train Loss: 2.5933, Train Accuracy: 26.17%, Train F1: 0.1181\n",
      "Epoch 6/12, Train Loss: 2.5459, Train Accuracy: 28.16%, Train F1: 0.1265\n",
      "Epoch 7/12, Train Loss: 2.5270, Train Accuracy: 28.44%, Train F1: 0.1326\n",
      "Epoch 8/12, Train Loss: 2.4678, Train Accuracy: 29.92%, Train F1: 0.1416\n",
      "Epoch 9/12, Train Loss: 2.4414, Train Accuracy: 30.62%, Train F1: 0.1443\n",
      "Epoch 10/12, Train Loss: 2.4232, Train Accuracy: 31.58%, Train F1: 0.1516\n",
      "Epoch 11/12, Train Loss: 2.3868, Train Accuracy: 32.41%, Train F1: 0.1608\n",
      "Epoch 12/12, Train Loss: 2.3562, Train Accuracy: 33.39%, Train F1: 0.1762\n",
      "Validation Loss: 8.4158, Accuracy: 5.83%, F1: 0.0238 with params: {'weight_decay': 1e-06, 'learning_rate': 0.1, 'epochs': 12, 'batch_size': 64}\n",
      "Best validation F1 score: 0.3950 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 2.7272, Train Accuracy: 25.64%, Train F1: 0.1006\n",
      "Epoch 2/10, Train Loss: 2.3170, Train Accuracy: 34.18%, Train F1: 0.1949\n",
      "Epoch 3/10, Train Loss: 2.1213, Train Accuracy: 39.34%, Train F1: 0.2529\n",
      "Epoch 4/10, Train Loss: 1.9574, Train Accuracy: 43.41%, Train F1: 0.2976\n",
      "Epoch 5/10, Train Loss: 1.8082, Train Accuracy: 47.78%, Train F1: 0.3469\n",
      "Epoch 6/10, Train Loss: 1.6640, Train Accuracy: 51.31%, Train F1: 0.3891\n",
      "Epoch 7/10, Train Loss: 1.5501, Train Accuracy: 54.37%, Train F1: 0.4280\n",
      "Epoch 8/10, Train Loss: 1.4487, Train Accuracy: 56.85%, Train F1: 0.4595\n",
      "Epoch 9/10, Train Loss: 1.3578, Train Accuracy: 59.56%, Train F1: 0.4964\n",
      "Epoch 10/10, Train Loss: 1.2905, Train Accuracy: 61.54%, Train F1: 0.5210\n",
      "Final Validation Loss: 1.9924, Accuracy: 43.62%, F1: 0.3328\n",
      "Training resnext50_32x4d...\n",
      "Epoch 1/8, Train Loss: 3.1497, Train Accuracy: 17.60%, Train F1: 0.0537\n",
      "Epoch 2/8, Train Loss: 2.6019, Train Accuracy: 23.85%, Train F1: 0.1136\n",
      "Epoch 3/8, Train Loss: 2.4497, Train Accuracy: 29.51%, Train F1: 0.1599\n",
      "Epoch 4/8, Train Loss: 2.3115, Train Accuracy: 33.85%, Train F1: 0.1995\n",
      "Epoch 5/8, Train Loss: 2.2009, Train Accuracy: 37.34%, Train F1: 0.2290\n",
      "Epoch 6/8, Train Loss: 2.0570, Train Accuracy: 40.64%, Train F1: 0.2708\n",
      "Epoch 7/8, Train Loss: 1.9502, Train Accuracy: 43.56%, Train F1: 0.3039\n",
      "Epoch 8/8, Train Loss: 1.8274, Train Accuracy: 46.60%, Train F1: 0.3485\n",
      "Validation Loss: 2.3924, Accuracy: 36.64%, F1: 0.2727 with params: {'weight_decay': 1e-06, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.6404, Train Accuracy: 29.16%, Train F1: 0.1237\n",
      "Epoch 2/10, Train Loss: 2.1738, Train Accuracy: 38.27%, Train F1: 0.2437\n",
      "Epoch 3/10, Train Loss: 1.9183, Train Accuracy: 44.57%, Train F1: 0.3198\n",
      "Epoch 4/10, Train Loss: 1.7484, Train Accuracy: 49.83%, Train F1: 0.3744\n",
      "Epoch 5/10, Train Loss: 1.5399, Train Accuracy: 54.78%, Train F1: 0.4317\n",
      "Epoch 6/10, Train Loss: 1.4614, Train Accuracy: 56.85%, Train F1: 0.4646\n",
      "Epoch 7/10, Train Loss: 1.3188, Train Accuracy: 60.48%, Train F1: 0.5084\n",
      "Epoch 8/10, Train Loss: 1.2128, Train Accuracy: 63.62%, Train F1: 0.5479\n",
      "Epoch 9/10, Train Loss: 1.1176, Train Accuracy: 66.63%, Train F1: 0.5879\n",
      "Epoch 10/10, Train Loss: 1.0368, Train Accuracy: 68.88%, Train F1: 0.6145\n",
      "Validation Loss: 1.3907, Accuracy: 60.92%, F1: 0.4859 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/8, Train Loss: 3.1815, Train Accuracy: 17.82%, Train F1: 0.0551\n",
      "Epoch 2/8, Train Loss: 2.5969, Train Accuracy: 24.76%, Train F1: 0.1282\n",
      "Epoch 3/8, Train Loss: 2.4424, Train Accuracy: 30.50%, Train F1: 0.1649\n",
      "Epoch 4/8, Train Loss: 2.3213, Train Accuracy: 33.67%, Train F1: 0.1929\n",
      "Epoch 5/8, Train Loss: 2.1740, Train Accuracy: 37.96%, Train F1: 0.2406\n",
      "Epoch 6/8, Train Loss: 2.0449, Train Accuracy: 41.04%, Train F1: 0.2826\n",
      "Epoch 7/8, Train Loss: 1.8986, Train Accuracy: 44.67%, Train F1: 0.3188\n",
      "Epoch 8/8, Train Loss: 1.7990, Train Accuracy: 48.14%, Train F1: 0.3660\n",
      "Validation Loss: 1.9937, Accuracy: 42.88%, F1: 0.3262 with params: {'weight_decay': 1e-05, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 2.6100, Train Accuracy: 29.28%, Train F1: 0.1353\n",
      "Epoch 2/10, Train Loss: 2.0943, Train Accuracy: 39.99%, Train F1: 0.2670\n",
      "Epoch 3/10, Train Loss: 1.8626, Train Accuracy: 46.24%, Train F1: 0.3361\n",
      "Epoch 4/10, Train Loss: 1.6498, Train Accuracy: 51.85%, Train F1: 0.3989\n",
      "Epoch 5/10, Train Loss: 1.5280, Train Accuracy: 55.04%, Train F1: 0.4424\n",
      "Epoch 6/10, Train Loss: 1.3777, Train Accuracy: 59.76%, Train F1: 0.4940\n",
      "Epoch 7/10, Train Loss: 1.2682, Train Accuracy: 61.95%, Train F1: 0.5289\n",
      "Epoch 8/10, Train Loss: 1.1888, Train Accuracy: 64.32%, Train F1: 0.5535\n",
      "Epoch 9/10, Train Loss: 1.0574, Train Accuracy: 68.37%, Train F1: 0.6072\n",
      "Epoch 10/10, Train Loss: 0.9493, Train Accuracy: 71.01%, Train F1: 0.6431\n",
      "Validation Loss: 1.4338, Accuracy: 61.26%, F1: 0.4891 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/12, Train Loss: 3.6668, Train Accuracy: 16.35%, Train F1: 0.0558\n",
      "Epoch 2/12, Train Loss: 2.6793, Train Accuracy: 22.62%, Train F1: 0.0973\n",
      "Epoch 3/12, Train Loss: 2.5877, Train Accuracy: 26.40%, Train F1: 0.1293\n",
      "Epoch 4/12, Train Loss: 2.4613, Train Accuracy: 29.84%, Train F1: 0.1531\n",
      "Epoch 5/12, Train Loss: 2.4225, Train Accuracy: 31.05%, Train F1: 0.1702\n",
      "Epoch 6/12, Train Loss: 2.2799, Train Accuracy: 35.43%, Train F1: 0.2063\n",
      "Epoch 7/12, Train Loss: 2.2258, Train Accuracy: 36.55%, Train F1: 0.2225\n",
      "Epoch 8/12, Train Loss: 2.1199, Train Accuracy: 38.89%, Train F1: 0.2402\n",
      "Epoch 9/12, Train Loss: 2.0821, Train Accuracy: 40.24%, Train F1: 0.2564\n",
      "Epoch 10/12, Train Loss: 2.0346, Train Accuracy: 42.37%, Train F1: 0.2761\n",
      "Epoch 11/12, Train Loss: 2.0009, Train Accuracy: 42.92%, Train F1: 0.2848\n",
      "Epoch 12/12, Train Loss: 1.9712, Train Accuracy: 42.99%, Train F1: 0.2918\n",
      "Validation Loss: 11.5213, Accuracy: 9.02%, F1: 0.0410 with params: {'weight_decay': 1e-06, 'learning_rate': 0.1, 'epochs': 12, 'batch_size': 64}\n",
      "Best validation F1 score: 0.4891 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.6259, Train Accuracy: 28.90%, Train F1: 0.1663\n",
      "Epoch 2/10, Train Loss: 2.1272, Train Accuracy: 38.93%, Train F1: 0.2632\n",
      "Epoch 3/10, Train Loss: 1.8748, Train Accuracy: 45.99%, Train F1: 0.3336\n",
      "Epoch 4/10, Train Loss: 1.7350, Train Accuracy: 49.46%, Train F1: 0.3742\n",
      "Epoch 5/10, Train Loss: 1.5525, Train Accuracy: 54.47%, Train F1: 0.4412\n",
      "Epoch 6/10, Train Loss: 1.4243, Train Accuracy: 57.39%, Train F1: 0.4722\n",
      "Epoch 7/10, Train Loss: 1.2948, Train Accuracy: 60.91%, Train F1: 0.5177\n",
      "Epoch 8/10, Train Loss: 1.1851, Train Accuracy: 64.48%, Train F1: 0.5619\n",
      "Epoch 9/10, Train Loss: 1.1019, Train Accuracy: 66.45%, Train F1: 0.5863\n",
      "Epoch 10/10, Train Loss: 1.0042, Train Accuracy: 68.99%, Train F1: 0.6210\n",
      "Final Validation Loss: 1.7354, Accuracy: 59.43%, F1: 0.4947\n",
      "Training wide_resnet50_2...\n",
      "Epoch 1/8, Train Loss: 3.2498, Train Accuracy: 17.64%, Train F1: 0.0606\n",
      "Epoch 2/8, Train Loss: 2.6553, Train Accuracy: 22.94%, Train F1: 0.1066\n",
      "Epoch 3/8, Train Loss: 2.5093, Train Accuracy: 28.13%, Train F1: 0.1420\n",
      "Epoch 4/8, Train Loss: 2.3758, Train Accuracy: 32.31%, Train F1: 0.1751\n",
      "Epoch 5/8, Train Loss: 2.2813, Train Accuracy: 35.10%, Train F1: 0.1989\n",
      "Epoch 6/8, Train Loss: 2.2033, Train Accuracy: 36.65%, Train F1: 0.2191\n",
      "Epoch 7/8, Train Loss: 2.0965, Train Accuracy: 39.76%, Train F1: 0.2553\n",
      "Epoch 8/8, Train Loss: 1.9963, Train Accuracy: 41.79%, Train F1: 0.2837\n",
      "Validation Loss: 2.3365, Accuracy: 36.84%, F1: 0.2317 with params: {'weight_decay': 1e-06, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.8117, Train Accuracy: 24.05%, Train F1: 0.0973\n",
      "Epoch 2/10, Train Loss: 2.3623, Train Accuracy: 33.28%, Train F1: 0.1844\n",
      "Epoch 3/10, Train Loss: 2.1773, Train Accuracy: 38.00%, Train F1: 0.2354\n",
      "Epoch 4/10, Train Loss: 2.0176, Train Accuracy: 41.22%, Train F1: 0.2772\n",
      "Epoch 5/10, Train Loss: 1.8883, Train Accuracy: 45.08%, Train F1: 0.3241\n",
      "Epoch 6/10, Train Loss: 1.7532, Train Accuracy: 49.11%, Train F1: 0.3769\n",
      "Epoch 7/10, Train Loss: 1.6709, Train Accuracy: 51.09%, Train F1: 0.4027\n",
      "Epoch 8/10, Train Loss: 1.5316, Train Accuracy: 55.36%, Train F1: 0.4507\n",
      "Epoch 9/10, Train Loss: 1.4284, Train Accuracy: 57.80%, Train F1: 0.4824\n",
      "Epoch 10/10, Train Loss: 1.3479, Train Accuracy: 60.48%, Train F1: 0.5196\n",
      "Validation Loss: 1.8049, Accuracy: 51.63%, F1: 0.4026 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/8, Train Loss: 3.2234, Train Accuracy: 17.90%, Train F1: 0.0660\n",
      "Epoch 2/8, Train Loss: 2.6161, Train Accuracy: 24.41%, Train F1: 0.1236\n",
      "Epoch 3/8, Train Loss: 2.5017, Train Accuracy: 28.32%, Train F1: 0.1459\n",
      "Epoch 4/8, Train Loss: 2.4047, Train Accuracy: 31.55%, Train F1: 0.1713\n",
      "Epoch 5/8, Train Loss: 2.3433, Train Accuracy: 33.36%, Train F1: 0.1918\n",
      "Epoch 6/8, Train Loss: 2.2407, Train Accuracy: 36.74%, Train F1: 0.2182\n",
      "Epoch 7/8, Train Loss: 2.1602, Train Accuracy: 38.27%, Train F1: 0.2364\n",
      "Epoch 8/8, Train Loss: 2.0457, Train Accuracy: 41.64%, Train F1: 0.2767\n",
      "Validation Loss: 2.0492, Accuracy: 40.91%, F1: 0.2407 with params: {'weight_decay': 1e-05, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 2.6980, Train Accuracy: 26.71%, Train F1: 0.1138\n",
      "Epoch 2/10, Train Loss: 2.3155, Train Accuracy: 33.98%, Train F1: 0.1997\n",
      "Epoch 3/10, Train Loss: 2.0890, Train Accuracy: 39.76%, Train F1: 0.2627\n",
      "Epoch 4/10, Train Loss: 1.9716, Train Accuracy: 42.87%, Train F1: 0.2933\n",
      "Epoch 5/10, Train Loss: 1.8027, Train Accuracy: 47.32%, Train F1: 0.3482\n",
      "Epoch 6/10, Train Loss: 1.6794, Train Accuracy: 50.36%, Train F1: 0.3839\n",
      "Epoch 7/10, Train Loss: 1.5796, Train Accuracy: 53.36%, Train F1: 0.4243\n",
      "Epoch 8/10, Train Loss: 1.4885, Train Accuracy: 55.72%, Train F1: 0.4535\n",
      "Epoch 9/10, Train Loss: 1.4151, Train Accuracy: 58.31%, Train F1: 0.4859\n",
      "Epoch 10/10, Train Loss: 1.2878, Train Accuracy: 61.31%, Train F1: 0.5208\n",
      "Validation Loss: 1.5766, Accuracy: 54.27%, F1: 0.4334 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/12, Train Loss: 4.2648, Train Accuracy: 15.41%, Train F1: 0.0555\n",
      "Epoch 2/12, Train Loss: 2.7227, Train Accuracy: 20.83%, Train F1: 0.0936\n",
      "Epoch 3/12, Train Loss: 2.6622, Train Accuracy: 22.69%, Train F1: 0.1045\n",
      "Epoch 4/12, Train Loss: 2.5765, Train Accuracy: 25.25%, Train F1: 0.1206\n",
      "Epoch 5/12, Train Loss: 2.5387, Train Accuracy: 27.32%, Train F1: 0.1288\n",
      "Epoch 6/12, Train Loss: 2.5260, Train Accuracy: 28.38%, Train F1: 0.1353\n",
      "Epoch 7/12, Train Loss: 2.4836, Train Accuracy: 30.29%, Train F1: 0.1486\n",
      "Epoch 8/12, Train Loss: 2.4566, Train Accuracy: 30.04%, Train F1: 0.1416\n",
      "Epoch 9/12, Train Loss: 2.4301, Train Accuracy: 31.59%, Train F1: 0.1517\n",
      "Epoch 10/12, Train Loss: 2.4172, Train Accuracy: 31.57%, Train F1: 0.1520\n",
      "Epoch 11/12, Train Loss: 2.3873, Train Accuracy: 33.00%, Train F1: 0.1624\n",
      "Epoch 12/12, Train Loss: 2.3588, Train Accuracy: 34.07%, Train F1: 0.1659\n",
      "Validation Loss: 3.4198, Accuracy: 16.01%, F1: 0.0768 with params: {'weight_decay': 1e-06, 'learning_rate': 0.1, 'epochs': 12, 'batch_size': 64}\n",
      "Best validation F1 score: 0.4334 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 2.7114, Train Accuracy: 25.75%, Train F1: 0.1145\n",
      "Epoch 2/10, Train Loss: 2.3338, Train Accuracy: 33.77%, Train F1: 0.2018\n",
      "Epoch 3/10, Train Loss: 2.1341, Train Accuracy: 38.02%, Train F1: 0.2478\n",
      "Epoch 4/10, Train Loss: 1.9455, Train Accuracy: 43.33%, Train F1: 0.3090\n",
      "Epoch 5/10, Train Loss: 1.8013, Train Accuracy: 47.28%, Train F1: 0.3535\n",
      "Epoch 6/10, Train Loss: 1.6768, Train Accuracy: 50.92%, Train F1: 0.3946\n",
      "Epoch 7/10, Train Loss: 1.5793, Train Accuracy: 54.00%, Train F1: 0.4280\n",
      "Epoch 8/10, Train Loss: 1.4656, Train Accuracy: 56.50%, Train F1: 0.4572\n",
      "Epoch 9/10, Train Loss: 1.3600, Train Accuracy: 59.82%, Train F1: 0.5044\n",
      "Epoch 10/10, Train Loss: 1.2620, Train Accuracy: 62.67%, Train F1: 0.5389\n",
      "Final Validation Loss: 2.5219, Accuracy: 44.03%, F1: 0.2756\n",
      "Training alexnet...\n",
      "Epoch 1/8, Train Loss: 11347.9226, Train Accuracy: 11.55%, Train F1: 0.0139\n",
      "Epoch 2/8, Train Loss: 3.0373, Train Accuracy: 11.75%, Train F1: 0.0196\n",
      "Epoch 3/8, Train Loss: 3.0278, Train Accuracy: 11.80%, Train F1: 0.0196\n",
      "Epoch 4/8, Train Loss: 3.0228, Train Accuracy: 12.09%, Train F1: 0.0201\n",
      "Epoch 5/8, Train Loss: 3.0216, Train Accuracy: 11.97%, Train F1: 0.0182\n",
      "Epoch 6/8, Train Loss: 3.0177, Train Accuracy: 11.59%, Train F1: 0.0168\n",
      "Epoch 7/8, Train Loss: 3.0177, Train Accuracy: 12.11%, Train F1: 0.0185\n",
      "Epoch 8/8, Train Loss: 3.0143, Train Accuracy: 11.64%, Train F1: 0.0157\n",
      "Validation Loss: 3.0117, Accuracy: 12.35%, F1: 0.0085 with params: {'weight_decay': 1e-06, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 4.2225, Train Accuracy: 11.28%, Train F1: 0.0133\n",
      "Epoch 2/10, Train Loss: 3.0304, Train Accuracy: 11.48%, Train F1: 0.0190\n",
      "Epoch 3/10, Train Loss: 3.0256, Train Accuracy: 11.79%, Train F1: 0.0166\n",
      "Epoch 4/10, Train Loss: 3.0240, Train Accuracy: 12.03%, Train F1: 0.0188\n",
      "Epoch 5/10, Train Loss: 3.0237, Train Accuracy: 11.44%, Train F1: 0.0195\n",
      "Epoch 6/10, Train Loss: 3.0231, Train Accuracy: 11.65%, Train F1: 0.0178\n",
      "Epoch 7/10, Train Loss: 3.0194, Train Accuracy: 12.21%, Train F1: 0.0197\n",
      "Epoch 8/10, Train Loss: 3.0196, Train Accuracy: 11.91%, Train F1: 0.0190\n",
      "Epoch 9/10, Train Loss: 3.0174, Train Accuracy: 11.83%, Train F1: 0.0191\n",
      "Epoch 10/10, Train Loss: 3.0181, Train Accuracy: 11.62%, Train F1: 0.0191\n",
      "Validation Loss: 3.0142, Accuracy: 12.35%, F1: 0.0085 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/8, Train Loss: 6608.8657, Train Accuracy: 11.06%, Train F1: 0.0151\n",
      "Epoch 2/8, Train Loss: 3.0454, Train Accuracy: 11.26%, Train F1: 0.0218\n",
      "Epoch 3/8, Train Loss: 3.0381, Train Accuracy: 11.31%, Train F1: 0.0190\n",
      "Epoch 4/8, Train Loss: 3.0340, Train Accuracy: 11.70%, Train F1: 0.0208\n",
      "Epoch 5/8, Train Loss: 3.0301, Train Accuracy: 11.72%, Train F1: 0.0198\n",
      "Epoch 6/8, Train Loss: 3.0316, Train Accuracy: 11.84%, Train F1: 0.0194\n",
      "Epoch 7/8, Train Loss: 3.0276, Train Accuracy: 11.94%, Train F1: 0.0197\n",
      "Epoch 8/8, Train Loss: 3.0303, Train Accuracy: 12.37%, Train F1: 0.0203\n",
      "Validation Loss: 3.0202, Accuracy: 11.60%, F1: 0.0080 with params: {'weight_decay': 1e-05, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 4.0418, Train Accuracy: 11.83%, Train F1: 0.0139\n",
      "Epoch 2/10, Train Loss: 2.8454, Train Accuracy: 18.10%, Train F1: 0.0465\n",
      "Epoch 3/10, Train Loss: 2.7062, Train Accuracy: 21.47%, Train F1: 0.0648\n",
      "Epoch 4/10, Train Loss: 2.5895, Train Accuracy: 24.63%, Train F1: 0.0922\n",
      "Epoch 5/10, Train Loss: 2.4248, Train Accuracy: 29.43%, Train F1: 0.1307\n",
      "Epoch 6/10, Train Loss: 2.2397, Train Accuracy: 35.60%, Train F1: 0.1865\n",
      "Epoch 7/10, Train Loss: 2.0778, Train Accuracy: 40.15%, Train F1: 0.2325\n",
      "Epoch 8/10, Train Loss: 1.9663, Train Accuracy: 43.07%, Train F1: 0.2654\n",
      "Epoch 9/10, Train Loss: 1.8613, Train Accuracy: 45.44%, Train F1: 0.2945\n",
      "Epoch 10/10, Train Loss: 1.7613, Train Accuracy: 47.90%, Train F1: 0.3305\n",
      "Validation Loss: 1.8528, Accuracy: 48.71%, F1: 0.3231 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/12, Train Loss: 432409411296.3625, Train Accuracy: 8.77%, Train F1: 0.0171\n",
      "Epoch 2/12, Train Loss: 1767590.2102, Train Accuracy: 10.59%, Train F1: 0.0272\n",
      "Epoch 3/12, Train Loss: 53.1621, Train Accuracy: 11.66%, Train F1: 0.0171\n",
      "Epoch 4/12, Train Loss: 111.2290, Train Accuracy: 11.44%, Train F1: 0.0175\n",
      "Epoch 5/12, Train Loss: 158.9920, Train Accuracy: 11.64%, Train F1: 0.0159\n",
      "Epoch 6/12, Train Loss: 16.0750, Train Accuracy: 12.61%, Train F1: 0.0196\n",
      "Epoch 7/12, Train Loss: 3481.0170, Train Accuracy: 12.05%, Train F1: 0.0174\n",
      "Epoch 8/12, Train Loss: 51.0245, Train Accuracy: 12.06%, Train F1: 0.0197\n",
      "Epoch 9/12, Train Loss: 4.3660, Train Accuracy: 12.24%, Train F1: 0.0194\n",
      "Epoch 10/12, Train Loss: 63.6631, Train Accuracy: 11.87%, Train F1: 0.0188\n",
      "Epoch 11/12, Train Loss: 5.3615, Train Accuracy: 11.72%, Train F1: 0.0182\n",
      "Epoch 12/12, Train Loss: 3.0882, Train Accuracy: 11.91%, Train F1: 0.0178\n",
      "Validation Loss: 3.0224, Accuracy: 12.35%, F1: 0.0085 with params: {'weight_decay': 1e-06, 'learning_rate': 0.1, 'epochs': 12, 'batch_size': 64}\n",
      "Best validation F1 score: 0.3231 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 4.1322, Train Accuracy: 13.53%, Train F1: 0.0284\n",
      "Epoch 2/10, Train Loss: 2.6887, Train Accuracy: 22.01%, Train F1: 0.0848\n",
      "Epoch 3/10, Train Loss: 2.4769, Train Accuracy: 28.75%, Train F1: 0.1300\n",
      "Epoch 4/10, Train Loss: 2.2616, Train Accuracy: 35.57%, Train F1: 0.1863\n",
      "Epoch 5/10, Train Loss: 2.0859, Train Accuracy: 39.80%, Train F1: 0.2283\n",
      "Epoch 6/10, Train Loss: 1.9513, Train Accuracy: 43.58%, Train F1: 0.2729\n",
      "Epoch 7/10, Train Loss: 1.8322, Train Accuracy: 47.01%, Train F1: 0.3129\n",
      "Epoch 8/10, Train Loss: 1.7192, Train Accuracy: 49.48%, Train F1: 0.3527\n",
      "Epoch 9/10, Train Loss: 1.6257, Train Accuracy: 51.95%, Train F1: 0.3841\n",
      "Epoch 10/10, Train Loss: 1.5229, Train Accuracy: 54.28%, Train F1: 0.4180\n",
      "Final Validation Loss: 1.5852, Accuracy: 51.36%, F1: 0.3727\n",
      "Training squeezenet1_0...\n",
      "Epoch 1/8, Train Loss: 14.8694, Train Accuracy: 11.78%, Train F1: 0.0110\n",
      "Epoch 2/8, Train Loss: 4.5060, Train Accuracy: 12.32%, Train F1: 0.0084\n",
      "Epoch 3/8, Train Loss: 4.5061, Train Accuracy: 12.32%, Train F1: 0.0084\n",
      "Epoch 4/8, Train Loss: 4.5098, Train Accuracy: 12.29%, Train F1: 0.0084\n",
      "Epoch 5/8, Train Loss: 4.5106, Train Accuracy: 12.32%, Train F1: 0.0084\n",
      "Epoch 6/8, Train Loss: 4.5080, Train Accuracy: 12.32%, Train F1: 0.0084\n",
      "Epoch 7/8, Train Loss: 4.5116, Train Accuracy: 12.32%, Train F1: 0.0084\n",
      "Epoch 8/8, Train Loss: 4.5074, Train Accuracy: 12.32%, Train F1: 0.0084\n",
      "Validation Loss: 4.5739, Accuracy: 12.35%, F1: 0.0085 with params: {'weight_decay': 1e-06, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 128}\n",
      "Epoch 1/10, Train Loss: 3.1131, Train Accuracy: 15.07%, Train F1: 0.0388\n",
      "Epoch 2/10, Train Loss: 2.7900, Train Accuracy: 18.94%, Train F1: 0.0709\n",
      "Epoch 3/10, Train Loss: 2.6355, Train Accuracy: 23.70%, Train F1: 0.1006\n",
      "Epoch 4/10, Train Loss: 2.4362, Train Accuracy: 30.58%, Train F1: 0.1465\n",
      "Epoch 5/10, Train Loss: 2.3314, Train Accuracy: 33.42%, Train F1: 0.1768\n",
      "Epoch 6/10, Train Loss: 2.1957, Train Accuracy: 37.68%, Train F1: 0.2152\n",
      "Epoch 7/10, Train Loss: 2.1003, Train Accuracy: 39.57%, Train F1: 0.2439\n",
      "Epoch 8/10, Train Loss: 1.9827, Train Accuracy: 42.96%, Train F1: 0.2825\n",
      "Epoch 9/10, Train Loss: 1.9055, Train Accuracy: 44.94%, Train F1: 0.3096\n",
      "Epoch 10/10, Train Loss: 1.8266, Train Accuracy: 47.15%, Train F1: 0.3338\n",
      "Validation Loss: 1.8981, Accuracy: 48.24%, F1: 0.3563 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/8, Train Loss: 6.8891, Train Accuracy: 11.13%, Train F1: 0.0143\n",
      "Epoch 2/8, Train Loss: 4.1982, Train Accuracy: 11.55%, Train F1: 0.0142\n",
      "Epoch 3/8, Train Loss: 4.1972, Train Accuracy: 11.04%, Train F1: 0.0124\n",
      "Epoch 4/8, Train Loss: 4.2056, Train Accuracy: 11.44%, Train F1: 0.0131\n",
      "Epoch 5/8, Train Loss: 4.1990, Train Accuracy: 11.15%, Train F1: 0.0140\n",
      "Epoch 6/8, Train Loss: 4.1994, Train Accuracy: 11.55%, Train F1: 0.0142\n",
      "Epoch 7/8, Train Loss: 4.1992, Train Accuracy: 11.17%, Train F1: 0.0128\n",
      "Epoch 8/8, Train Loss: 4.1992, Train Accuracy: 11.14%, Train F1: 0.0133\n",
      "Validation Loss: 4.1388, Accuracy: 11.60%, F1: 0.0080 with params: {'weight_decay': 1e-05, 'learning_rate': 0.01, 'epochs': 8, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 3.2798, Train Accuracy: 14.21%, Train F1: 0.0368\n",
      "Epoch 2/10, Train Loss: 2.9173, Train Accuracy: 19.34%, Train F1: 0.0649\n",
      "Epoch 3/10, Train Loss: 2.7850, Train Accuracy: 23.82%, Train F1: 0.0919\n",
      "Epoch 4/10, Train Loss: 2.6651, Train Accuracy: 26.48%, Train F1: 0.1193\n",
      "Epoch 5/10, Train Loss: 2.5203, Train Accuracy: 32.02%, Train F1: 0.1541\n",
      "Epoch 6/10, Train Loss: 2.4159, Train Accuracy: 34.34%, Train F1: 0.1830\n",
      "Epoch 7/10, Train Loss: 2.3000, Train Accuracy: 38.21%, Train F1: 0.2278\n",
      "Epoch 8/10, Train Loss: 2.1891, Train Accuracy: 41.28%, Train F1: 0.2651\n",
      "Epoch 9/10, Train Loss: 2.0959, Train Accuracy: 43.79%, Train F1: 0.2941\n",
      "Epoch 10/10, Train Loss: 1.9785, Train Accuracy: 45.93%, Train F1: 0.3228\n",
      "Validation Loss: 1.9212, Accuracy: 49.05%, F1: 0.3304 with params: {'weight_decay': 1e-06, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 128}\n",
      "Epoch 1/12, Train Loss: 28298695460935.4688, Train Accuracy: 10.73%, Train F1: 0.0203\n",
      "Epoch 2/12, Train Loss: 3.5838, Train Accuracy: 11.60%, Train F1: 0.0210\n",
      "Epoch 3/12, Train Loss: 3.5715, Train Accuracy: 11.83%, Train F1: 0.0196\n",
      "Epoch 4/12, Train Loss: 3.5517, Train Accuracy: 11.74%, Train F1: 0.0197\n",
      "Epoch 5/12, Train Loss: 3.5595, Train Accuracy: 11.61%, Train F1: 0.0194\n",
      "Epoch 6/12, Train Loss: 3.5537, Train Accuracy: 11.64%, Train F1: 0.0218\n",
      "Epoch 7/12, Train Loss: 3.5526, Train Accuracy: 11.66%, Train F1: 0.0206\n",
      "Epoch 8/12, Train Loss: 3.4465, Train Accuracy: 11.27%, Train F1: 0.0202\n",
      "Epoch 9/12, Train Loss: 2620.6820, Train Accuracy: 11.49%, Train F1: 0.0222\n",
      "Epoch 10/12, Train Loss: 3.4382, Train Accuracy: 11.72%, Train F1: 0.0209\n",
      "Epoch 11/12, Train Loss: 3.4444, Train Accuracy: 12.05%, Train F1: 0.0205\n",
      "Epoch 12/12, Train Loss: 3.4375, Train Accuracy: 11.60%, Train F1: 0.0207\n",
      "Validation Loss: 3.4193, Accuracy: 12.35%, F1: 0.0085 with params: {'weight_decay': 1e-06, 'learning_rate': 0.1, 'epochs': 12, 'batch_size': 64}\n",
      "Best validation F1 score: 0.3563 with params: {'weight_decay': 1e-05, 'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32}\n",
      "Epoch 1/10, Train Loss: 3.3853, Train Accuracy: 11.38%, Train F1: 0.0218\n",
      "Epoch 2/10, Train Loss: 3.0187, Train Accuracy: 18.14%, Train F1: 0.0574\n",
      "Epoch 3/10, Train Loss: 2.8404, Train Accuracy: 20.61%, Train F1: 0.0872\n",
      "Epoch 4/10, Train Loss: 2.5719, Train Accuracy: 25.13%, Train F1: 0.1172\n",
      "Epoch 5/10, Train Loss: 2.4368, Train Accuracy: 28.45%, Train F1: 0.1443\n",
      "Epoch 6/10, Train Loss: 2.3465, Train Accuracy: 31.89%, Train F1: 0.1739\n",
      "Epoch 7/10, Train Loss: 2.2391, Train Accuracy: 35.05%, Train F1: 0.2031\n",
      "Epoch 8/10, Train Loss: 2.1473, Train Accuracy: 38.00%, Train F1: 0.2338\n",
      "Epoch 9/10, Train Loss: 2.0480, Train Accuracy: 40.25%, Train F1: 0.2616\n",
      "Epoch 10/10, Train Loss: 1.9871, Train Accuracy: 42.09%, Train F1: 0.2795\n",
      "Final Validation Loss: 1.9346, Accuracy: 44.78%, F1: 0.2820\n",
      "Ensemble Validation F1 Score: 0.1394\n",
      "Epoch 1/10, Train Loss: 2.4705, Train Accuracy: 31.64%, Train F1: 0.1357\n",
      "Epoch 2/10, Train Loss: 2.0780, Train Accuracy: 40.13%, Train F1: 0.2688\n",
      "Epoch 3/10, Train Loss: 1.8729, Train Accuracy: 45.40%, Train F1: 0.3311\n",
      "Epoch 4/10, Train Loss: 1.7195, Train Accuracy: 48.89%, Train F1: 0.3785\n",
      "Epoch 5/10, Train Loss: 1.5683, Train Accuracy: 53.65%, Train F1: 0.4324\n",
      "Epoch 6/10, Train Loss: 1.4249, Train Accuracy: 57.67%, Train F1: 0.4843\n",
      "Epoch 7/10, Train Loss: 1.2907, Train Accuracy: 61.48%, Train F1: 0.5288\n",
      "Epoch 8/10, Train Loss: 1.1495, Train Accuracy: 64.89%, Train F1: 0.5724\n",
      "Epoch 9/10, Train Loss: 1.0456, Train Accuracy: 68.53%, Train F1: 0.6151\n",
      "Epoch 10/10, Train Loss: 0.9270, Train Accuracy: 71.53%, Train F1: 0.6492\n",
      "Epoch 1/10, Train Loss: 2.7355, Train Accuracy: 25.82%, Train F1: 0.1055\n",
      "Epoch 2/10, Train Loss: 2.2468, Train Accuracy: 35.79%, Train F1: 0.2215\n",
      "Epoch 3/10, Train Loss: 2.0284, Train Accuracy: 41.66%, Train F1: 0.2848\n",
      "Epoch 4/10, Train Loss: 1.8607, Train Accuracy: 45.95%, Train F1: 0.3362\n",
      "Epoch 5/10, Train Loss: 1.7093, Train Accuracy: 49.98%, Train F1: 0.3835\n",
      "Epoch 6/10, Train Loss: 1.5811, Train Accuracy: 53.72%, Train F1: 0.4268\n",
      "Epoch 7/10, Train Loss: 1.4876, Train Accuracy: 56.26%, Train F1: 0.4597\n",
      "Epoch 8/10, Train Loss: 1.3953, Train Accuracy: 58.34%, Train F1: 0.4870\n",
      "Epoch 9/10, Train Loss: 1.2997, Train Accuracy: 61.45%, Train F1: 0.5264\n",
      "Epoch 10/10, Train Loss: 1.2127, Train Accuracy: 64.03%, Train F1: 0.5602\n",
      "Epoch 1/10, Train Loss: 2.3354, Train Accuracy: 35.65%, Train F1: 0.1377\n",
      "Epoch 2/10, Train Loss: 1.8689, Train Accuracy: 45.94%, Train F1: 0.3184\n",
      "Epoch 3/10, Train Loss: 1.6434, Train Accuracy: 51.77%, Train F1: 0.3907\n",
      "Epoch 4/10, Train Loss: 1.4772, Train Accuracy: 56.48%, Train F1: 0.4497\n",
      "Epoch 5/10, Train Loss: 1.3516, Train Accuracy: 59.83%, Train F1: 0.4926\n",
      "Epoch 6/10, Train Loss: 1.2536, Train Accuracy: 62.87%, Train F1: 0.5383\n",
      "Epoch 7/10, Train Loss: 1.1502, Train Accuracy: 65.38%, Train F1: 0.5686\n",
      "Epoch 8/10, Train Loss: 1.0639, Train Accuracy: 67.66%, Train F1: 0.6015\n",
      "Epoch 9/10, Train Loss: 0.9817, Train Accuracy: 70.57%, Train F1: 0.6339\n",
      "Epoch 10/10, Train Loss: 0.9172, Train Accuracy: 72.37%, Train F1: 0.6570\n",
      "Epoch 1/10, Train Loss: 2.5429, Train Accuracy: 30.11%, Train F1: 0.0910\n",
      "Epoch 2/10, Train Loss: 2.1055, Train Accuracy: 39.88%, Train F1: 0.2391\n",
      "Epoch 3/10, Train Loss: 1.8624, Train Accuracy: 45.77%, Train F1: 0.3163\n",
      "Epoch 4/10, Train Loss: 1.6966, Train Accuracy: 50.19%, Train F1: 0.3778\n",
      "Epoch 5/10, Train Loss: 1.5324, Train Accuracy: 54.37%, Train F1: 0.4223\n",
      "Epoch 6/10, Train Loss: 1.4087, Train Accuracy: 57.75%, Train F1: 0.4706\n",
      "Epoch 7/10, Train Loss: 1.2820, Train Accuracy: 61.53%, Train F1: 0.5176\n",
      "Epoch 8/10, Train Loss: 1.1773, Train Accuracy: 64.43%, Train F1: 0.5528\n",
      "Epoch 9/10, Train Loss: 1.0796, Train Accuracy: 66.81%, Train F1: 0.5836\n",
      "Epoch 10/10, Train Loss: 0.9972, Train Accuracy: 69.51%, Train F1: 0.6219\n",
      "Epoch 1/10, Train Loss: 2.7323, Train Accuracy: 24.80%, Train F1: 0.1107\n",
      "Epoch 2/10, Train Loss: 2.3470, Train Accuracy: 33.53%, Train F1: 0.1871\n",
      "Epoch 3/10, Train Loss: 2.1589, Train Accuracy: 38.47%, Train F1: 0.2382\n",
      "Epoch 4/10, Train Loss: 2.0376, Train Accuracy: 41.22%, Train F1: 0.2748\n",
      "Epoch 5/10, Train Loss: 1.8602, Train Accuracy: 46.11%, Train F1: 0.3268\n",
      "Epoch 6/10, Train Loss: 1.7596, Train Accuracy: 48.15%, Train F1: 0.3541\n",
      "Epoch 7/10, Train Loss: 1.6227, Train Accuracy: 52.37%, Train F1: 0.4046\n",
      "Epoch 8/10, Train Loss: 1.5653, Train Accuracy: 54.27%, Train F1: 0.4274\n",
      "Epoch 9/10, Train Loss: 1.6595, Train Accuracy: 51.37%, Train F1: 0.4016\n",
      "Epoch 10/10, Train Loss: 1.4420, Train Accuracy: 56.75%, Train F1: 0.4681\n",
      "Epoch 1/10, Train Loss: 2.6584, Train Accuracy: 28.73%, Train F1: 0.1329\n",
      "Epoch 2/10, Train Loss: 2.1189, Train Accuracy: 39.04%, Train F1: 0.2573\n",
      "Epoch 3/10, Train Loss: 1.9539, Train Accuracy: 43.88%, Train F1: 0.3087\n",
      "Epoch 4/10, Train Loss: 1.7121, Train Accuracy: 50.38%, Train F1: 0.3843\n",
      "Epoch 5/10, Train Loss: 1.5472, Train Accuracy: 54.61%, Train F1: 0.4369\n",
      "Epoch 6/10, Train Loss: 1.4081, Train Accuracy: 58.29%, Train F1: 0.4841\n",
      "Epoch 7/10, Train Loss: 1.2805, Train Accuracy: 61.73%, Train F1: 0.5203\n",
      "Epoch 8/10, Train Loss: 1.1864, Train Accuracy: 64.30%, Train F1: 0.5571\n",
      "Epoch 9/10, Train Loss: 1.0672, Train Accuracy: 67.56%, Train F1: 0.5997\n",
      "Epoch 10/10, Train Loss: 0.9944, Train Accuracy: 69.77%, Train F1: 0.6216\n",
      "Epoch 1/10, Train Loss: 2.7612, Train Accuracy: 24.96%, Train F1: 0.1162\n",
      "Epoch 2/10, Train Loss: 2.3356, Train Accuracy: 33.46%, Train F1: 0.1942\n",
      "Epoch 3/10, Train Loss: 2.1183, Train Accuracy: 38.98%, Train F1: 0.2546\n",
      "Epoch 4/10, Train Loss: 1.9942, Train Accuracy: 42.32%, Train F1: 0.2901\n",
      "Epoch 5/10, Train Loss: 1.8957, Train Accuracy: 44.83%, Train F1: 0.3096\n",
      "Epoch 6/10, Train Loss: 1.7101, Train Accuracy: 49.78%, Train F1: 0.3774\n",
      "Epoch 7/10, Train Loss: 1.5810, Train Accuracy: 53.72%, Train F1: 0.4225\n",
      "Epoch 8/10, Train Loss: 1.4853, Train Accuracy: 56.13%, Train F1: 0.4569\n",
      "Epoch 9/10, Train Loss: 1.3869, Train Accuracy: 59.10%, Train F1: 0.4974\n",
      "Epoch 10/10, Train Loss: 1.3127, Train Accuracy: 60.87%, Train F1: 0.5152\n",
      "Epoch 1/10, Train Loss: 4.0757, Train Accuracy: 12.99%, Train F1: 0.0155\n",
      "Epoch 2/10, Train Loss: 2.7636, Train Accuracy: 20.46%, Train F1: 0.0606\n",
      "Epoch 3/10, Train Loss: 2.6095, Train Accuracy: 24.55%, Train F1: 0.0946\n",
      "Epoch 4/10, Train Loss: 2.4295, Train Accuracy: 29.87%, Train F1: 0.1268\n",
      "Epoch 5/10, Train Loss: 2.2852, Train Accuracy: 34.26%, Train F1: 0.1771\n",
      "Epoch 6/10, Train Loss: 2.1627, Train Accuracy: 38.21%, Train F1: 0.2151\n",
      "Epoch 7/10, Train Loss: 2.0481, Train Accuracy: 41.02%, Train F1: 0.2460\n",
      "Epoch 8/10, Train Loss: 1.9416, Train Accuracy: 43.86%, Train F1: 0.2837\n",
      "Epoch 9/10, Train Loss: 1.8486, Train Accuracy: 46.51%, Train F1: 0.3108\n",
      "Epoch 10/10, Train Loss: 1.7680, Train Accuracy: 48.41%, Train F1: 0.3368\n",
      "Epoch 1/10, Train Loss: 3.2484, Train Accuracy: 14.88%, Train F1: 0.0342\n",
      "Epoch 2/10, Train Loss: 2.9360, Train Accuracy: 19.37%, Train F1: 0.0655\n",
      "Epoch 3/10, Train Loss: 2.7633, Train Accuracy: 24.93%, Train F1: 0.1062\n",
      "Epoch 4/10, Train Loss: 2.6273, Train Accuracy: 28.54%, Train F1: 0.1346\n",
      "Epoch 5/10, Train Loss: 2.4520, Train Accuracy: 33.88%, Train F1: 0.1794\n",
      "Epoch 6/10, Train Loss: 2.3369, Train Accuracy: 37.15%, Train F1: 0.2161\n",
      "Epoch 7/10, Train Loss: 2.2414, Train Accuracy: 39.81%, Train F1: 0.2494\n",
      "Epoch 8/10, Train Loss: 2.1185, Train Accuracy: 43.76%, Train F1: 0.2916\n",
      "Epoch 9/10, Train Loss: 2.0522, Train Accuracy: 45.33%, Train F1: 0.3153\n",
      "Epoch 10/10, Train Loss: 1.8817, Train Accuracy: 47.19%, Train F1: 0.3399\n",
      "Ensemble Test F1 Score: 0.1798\n",
      "Ensemble model saved to: ensemble_model.pth\n",
      "Ensemble model state dictionary saved to: transferlearning_ensemble_state_dict.pth\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 242\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnsemble model state dictionary saved to:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ensemble_state_dict_path)\n\u001b[1;32m    241\u001b[0m \u001b[38;5;66;03m# Create dataframe with training statistics\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m training_stats \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel\u001b[39m\u001b[38;5;124m'\u001b[39m: model_names,\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m: train_losses,\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: train_accuracies,\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain F1\u001b[39m\u001b[38;5;124m'\u001b[39m: train_f1_scores,\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Loss\u001b[39m\u001b[38;5;124m'\u001b[39m: val_loss,\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m: val_accuracy,\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVal F1\u001b[39m\u001b[38;5;124m'\u001b[39m: val_f1,\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBest Params\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28mstr\u001b[39m(model_params[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(model_names))]\n\u001b[1;32m    251\u001b[0m })\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    705\u001b[0m     )\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[1;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/internals/construction.py:655\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    653\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    654\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    657\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    658\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    659\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    660\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "\n",
    "class EnsembleModel(nn.Module):\n",
    "    def __init__(self, models):\n",
    "        super(EnsembleModel, self).__init__()\n",
    "        self.models = nn.ModuleList(models)\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = [model(x) for model in self.models]\n",
    "        return torch.mean(torch.stack(outputs), dim=0)\n",
    "\n",
    "# Define the preprocessing transformations\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((224, 224)),  # Resize images to match input size of models\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Often used for normalization in computer vision tasks\n",
    "])\n",
    "\n",
    "# Transpose the input data to be in the form [batch_size, num_channels, height, width]\n",
    "X_train_transposed = np.transpose(X_train, (0, 3, 1, 2))\n",
    "X_val_transposed = np.transpose(X_val, (0, 3, 1, 2))\n",
    "X_test_transposed = np.transpose(X_test, (0, 3, 1, 2))\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_transposed, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_val_tensor = torch.tensor(X_val_transposed, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test_transposed, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Models to try\n",
    "model_names = ['resnet18', 'resnet50', 'densenet121', 'mobilenet_v2',\n",
    "               'resnet101', 'resnext50_32x4d', 'wide_resnet50_2', 'alexnet', 'squeezenet1_0']\n",
    "\n",
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function for training a model\n",
    "def train_model(model, train_loader, optimizer, loss_func, device, epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    train_accuracies = []\n",
    "    train_f1_scores = []\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        predicted_labels = []\n",
    "        actual_labels = []\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad() # Set parameter gradients to 0\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            loss.backward() # Backpropagation\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted_label = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted_label == labels).sum().item()\n",
    "            predicted_labels.extend(predicted_label.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "        accuracy = correct / total\n",
    "        f1 = f1_score(actual_labels, predicted_labels, average='macro')\n",
    "        train_losses.append(running_loss / len(train_loader))\n",
    "        train_accuracies.append(accuracy)\n",
    "        train_f1_scores.append(f1)\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_losses[-1]:.4f}, Train Accuracy: {accuracy:.2%}, Train F1: {f1:.4f}\")\n",
    "\n",
    "    return train_losses, train_accuracies, train_f1_scores\n",
    "\n",
    "\n",
    "# Function for evaluating a model\n",
    "def evaluate_model(model, data_loader, loss_func, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predicted_labels = []\n",
    "    actual_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "            _, predicted_label = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted_label == labels).sum().item()\n",
    "            predicted_labels.extend(predicted_label.cpu().numpy())\n",
    "            actual_labels.extend(labels.cpu().numpy())\n",
    "    accuracy = correct / total\n",
    "    f1 = f1_score(actual_labels, predicted_labels, average='macro')\n",
    "    return running_loss / len(data_loader), accuracy, f1\n",
    "\n",
    "# Function for getting predictions of a model on a given data loader\n",
    "def get_predictions(model, data_loader, device):\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in data_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            predictions.extend(predicted_labels.cpu().numpy())\n",
    "    return predictions\n",
    "\n",
    "# Create empty dataframes to store predictions for validation and test sets\n",
    "val_predictions_df = pd.DataFrame(index=range(len(X_val)), columns=model_names)\n",
    "test_predictions_df = pd.DataFrame(index=range(len(X_test)), columns=model_names)\n",
    "\n",
    "# Define the parameter distributions for hyperparameter tuning\n",
    "param_distributions = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'epochs': [8, 10, 12, 14],\n",
    "    'batch_size': [32, 64, 128],\n",
    "    'weight_decay': [1e-4, 1e-5, 1e-6]\n",
    "}\n",
    "\n",
    "# Initialize model weights for ensembling\n",
    "model_weights = np.zeros(len(model_names))\n",
    "\n",
    "# Initialize dictionary to store best parameters for each model\n",
    "model_params = {}\n",
    "\n",
    "# Train and evaluate each model independently with hyperparameter tuning\n",
    "for model_idx, model_name in enumerate(model_names):\n",
    "    print(f\"Training {model_name}...\")\n",
    "\n",
    "    # Sample hyperparameters\n",
    "    param_sampler = ParameterSampler(param_distributions, n_iter=5, random_state=42)\n",
    "    best_params = None\n",
    "    best_f1_score = 0\n",
    "\n",
    "    for params in param_sampler:\n",
    "        # Create model, optimizer and loss function\n",
    "        model_class = getattr(models, model_name)\n",
    "        model = model_class().to(device)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=params['learning_rate'], weight_decay=params['weight_decay'])\n",
    "        loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "        # Train model\n",
    "        train_losses, train_accuracies, train_f1_scores = train_model(model, train_loader, optimizer, loss_func, device, params['epochs'])\n",
    "\n",
    "        # Evaluate model on validation set\n",
    "        val_loss, val_accuracy, val_f1 = evaluate_model(model, val_loader, loss_func, device)\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2%}, F1: {val_f1:.4f} with params: {params}\")\n",
    "\n",
    "        if val_f1 > best_f1_score:\n",
    "            best_f1_score = val_f1\n",
    "            best_params = params\n",
    "\n",
    "    print(f\"Best validation F1 score: {best_f1_score:.4f} with params: {best_params}\")\n",
    "\n",
    "    # Store best parameters\n",
    "    model_params[model_idx] = best_params\n",
    "\n",
    "    # Create model with best parameters\n",
    "    model = model_class().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=best_params['learning_rate'], weight_decay=best_params['weight_decay'])\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train model with best parameters\n",
    "    train_losses, train_accuracies, train_f1_scores = train_model(model, train_loader, optimizer, loss_func, device, best_params['epochs'])\n",
    "\n",
    "    # Evaluate model on validation set\n",
    "    val_loss, val_accuracy, val_f1 = evaluate_model(model, val_loader, loss_func, device)\n",
    "    print(f\"Final Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.2%}, F1: {val_f1:.4f}\")\n",
    "\n",
    "    # Store predictions on validation set for ensembling\n",
    "    val_predictions_df[model_name] = get_predictions(model, val_loader, device)\n",
    "\n",
    "    # Update model weights\n",
    "    model_weights[model_idx] = best_f1_score\n",
    "\n",
    "# Normalize model weights\n",
    "model_weights /= np.sum(model_weights)\n",
    "\n",
    "# Evaluate ensemble on validation set\n",
    "ensemble_predictions = np.zeros(len(X_val))\n",
    "for i, model_name in enumerate(model_names):\n",
    "    ensemble_predictions += val_predictions_df[model_name] * model_weights[i]\n",
    "\n",
    "ensemble_predictions = np.round(ensemble_predictions).astype(int)\n",
    "ensemble_val_f1 = f1_score(y_val, ensemble_predictions, average='macro')\n",
    "print(f\"Ensemble Validation F1 Score: {ensemble_val_f1:.4f}\")\n",
    "\n",
    "# Evaluate ensemble on test set\n",
    "test_predictions_df = pd.DataFrame(index=range(len(X_test)), columns=model_names)\n",
    "for model_idx, model_name in enumerate(model_names):\n",
    "    model_class = getattr(models, model_name)\n",
    "    model = model_class().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=model_params[model_idx]['learning_rate'], weight_decay=model_params[model_idx]['weight_decay'])\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    train_losses, train_accuracies, train_f1_scores = train_model(model, train_loader, optimizer, loss_func, device, model_params[model_idx]['epochs'])\n",
    "    test_predictions_df[model_name] = get_predictions(model, test_loader, device)\n",
    "\n",
    "# Ensemble predictions on test set\n",
    "ensemble_predictions_test = np.zeros(len(X_test))\n",
    "for i, model_name in enumerate(model_names):\n",
    "    ensemble_predictions_test += test_predictions_df[model_name] * model_weights[i]\n",
    "\n",
    "ensemble_predictions_test = np.round(ensemble_predictions_test).astype(int)\n",
    "ensemble_test_f1 = f1_score(y_test, ensemble_predictions_test, average='macro')\n",
    "print(f\"Ensemble Test F1 Score: {ensemble_test_f1:.4f}\")\n",
    "\n",
    "# Save the entire ensemble model\n",
    "ensemble_model_path = 'ensemble_model.pth'\n",
    "ensemble_model = EnsembleModel([getattr(models, model_name)().to(device) for model_name in model_names]).to(device)\n",
    "torch.save(ensemble_model, ensemble_model_path)\n",
    "print(\"Ensemble model saved to:\", ensemble_model_path)\n",
    "\n",
    "# Save ensemble model state dictionary to a file\n",
    "ensemble_state_dict_path = 'transferlearning_ensemble_state_dict.pth'\n",
    "ensemble_state_dict = {'model_names': model_names, 'model_params': model_params, 'model_weights': model_weights}\n",
    "torch.save(ensemble_state_dict, ensemble_state_dict_path)\n",
    "print(\"Ensemble model state dictionary saved to:\", ensemble_state_dict_path)\n",
    "\n",
    "# Create dataframe with training statistics\n",
    "training_stats = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Train Loss': train_losses,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Train F1': train_f1_scores,\n",
    "    'Val Loss': val_loss,\n",
    "    'Val Accuracy': val_accuracy,\n",
    "    'Val F1': val_f1,\n",
    "    'Best Params': [str(model_params[i]) for i in range(len(model_names))]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>Val F1</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model Train Loss Train Accuracy  Train F1  Val Loss Val Accuracy  \\\n",
       "0  Ellipsis   Ellipsis       Ellipsis  Ellipsis  Ellipsis     Ellipsis   \n",
       "\n",
       "     Val F1 Best Params  \n",
       "0  Ellipsis    Ellipsis  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming these arrays are correctly populated\n",
    "model_names = [...]  # List of model names\n",
    "train_losses = [...]  # List of training losses\n",
    "train_accuracies = [...]  # List of training accuracies\n",
    "train_f1_scores = [...]  # List of training F1 scores\n",
    "val_loss = [...]  # List of validation losses\n",
    "val_accuracy = [...]  # List of validation accuracies\n",
    "val_f1 = [...]  # List of validation F1 scores\n",
    "model_params = [...]  # List of model parameters\n",
    "\n",
    "# Create dataframe with training statistics\n",
    "training_stats = pd.DataFrame({\n",
    "    'Model': model_names,\n",
    "    'Train Loss': train_losses,\n",
    "    'Train Accuracy': train_accuracies,\n",
    "    'Train F1': train_f1_scores,\n",
    "    'Val Loss': val_loss,\n",
    "    'Val Accuracy': val_accuracy,\n",
    "    'Val F1': val_f1,\n",
    "    'Best Params': model_params\n",
    "})\n",
    "\n",
    "# Print or use training_stats DataFrame as needed\n",
    "training_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Names: [Ellipsis]\n",
      "Train Losses: [Ellipsis]\n",
      "Train Accuracies: [Ellipsis]\n",
      "Train F1 Scores: [Ellipsis]\n",
      "Validation Losses: [Ellipsis]\n",
      "Validation Accuracies: [Ellipsis]\n",
      "Validation F1 Scores: [Ellipsis]\n",
      "Model Parameters: [Ellipsis]\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Names:\", model_names)\n",
    "print(\"Train Losses:\", train_losses)\n",
    "print(\"Train Accuracies:\", train_accuracies)\n",
    "print(\"Train F1 Scores:\", train_f1_scores)\n",
    "print(\"Validation Losses:\", val_loss)\n",
    "print(\"Validation Accuracies:\", val_accuracy)\n",
    "print(\"Validation F1 Scores:\", val_f1)\n",
    "print(\"Model Parameters:\", model_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "mdIcRXXIurMj",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Train F1</th>\n",
       "      <th>Val Loss</th>\n",
       "      <th>Val Accuracy</th>\n",
       "      <th>Val F1</th>\n",
       "      <th>Best Params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>Ellipsis</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "def wrap_df_text(df):\n",
    "    return display(HTML(df.to_html().replace(\"\\\\n\",\"<br>\")))\n",
    "\n",
    "training_stats['Best Params'] = training_stats['Best Params'].str.wrap(30)\n",
    "wrap_df_text(training_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "kr9_KGqXuw-t",
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'resnet18_weights.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, model_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(model_names):\n\u001b[1;32m     16\u001b[0m     model \u001b[38;5;241m=\u001b[39m ensemble_model\u001b[38;5;241m.\u001b[39mmodels[i]\n\u001b[0;32m---> 17\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_weights.pth\u001b[39m\u001b[38;5;124m'\u001b[39m))  \u001b[38;5;66;03m# Load individual model weights\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:998\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    996\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 998\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _open_file_like(f, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m   1000\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m   1001\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m   1002\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m   1003\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:445\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _open_file(name_or_buffer, mode)\n\u001b[1;32m    446\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/serialization.py:426\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 426\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mopen\u001b[39m(name, mode))\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'resnet18_weights.pth'"
     ]
    }
   ],
   "source": [
    "ensemble_model_path = 'ensemble_model.pth'\n",
    "ensemble_state_dict_path = 'transferlearning_ensemble_state_dict.pth'\n",
    "ensemble_model = torch.load(ensemble_model_path)\n",
    "ensemble_state_dict = torch.load(ensemble_state_dict_path)\n",
    "\n",
    "# Create Ensemble Model Instance\n",
    "model_names = ensemble_state_dict['model_names']\n",
    "ensemble_model = EnsembleModel([getattr(models, model_name)().to(device) for model_name in model_names]).to(device)\n",
    "\n",
    "# Load Model Weights\n",
    "model_weights = ensemble_state_dict['model_weights']\n",
    "\n",
    "# Apply Model Weights to Validation Set\n",
    "ensemble_predictions_val = np.zeros(len(X_val))\n",
    "for i, model_name in enumerate(model_names):\n",
    "    model = ensemble_model.models[i]\n",
    "    model.load_state_dict(torch.load(f'{model_name}_weights.pth'))  # Load individual model weights\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, _ in val_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted_labels = torch.max(outputs, 1)\n",
    "            ensemble_predictions_val += predicted_labels.cpu().numpy() * model_weights[i]\n",
    "\n",
    "ensemble_predictions_val = np.round(ensemble_predictions_val).astype(int)\n",
    "ensemble_val_f1 = f1_score(y_val, ensemble_predictions_val, average='macro')\n",
    "print(f\"Ensemble Validation F1 Score after loading model weights: {ensemble_val_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3yoSX8RvvTq6"
   },
   "source": [
    "## VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dka349EHvUnA"
   },
   "outputs": [],
   "source": [
    "# Download image arrays from S3\n",
    "x_train = download_from_s3(s3_bucket_name, \"rgb_npy/train/rgb_224x224_train.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "y_train = download_from_s3(s3_bucket_name, \"rgb_npy/train/rgb_labels_train.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "x_val = download_from_s3(s3_bucket_name, \"rgb_npy/val/rgb_224x224_val.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "y_val = download_from_s3(s3_bucket_name, \"rgb_npy/val/rgb_labels_val.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "x_test = download_from_s3(s3_bucket_name, \"rgb_npy/test/rgb_224x224_test.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "y_test = download_from_s3(s3_bucket_name, \"rgb_npy/test/rgb_labels_test.npy\", aws_access_key_id, aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o_EQFPWOvZ37"
   },
   "outputs": [],
   "source": [
    "# String index the label names\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_val = le.fit_transform(y_val)\n",
    "y_test = le.fit_transform(y_test)\n",
    "\n",
    "# Can reverse this encoding: le.inverse_transform([9, 10, 1, 2])\n",
    "label_names = le.inverse_transform(range(26))\n",
    "print(\"Total number of classes:\", len(label_names))\n",
    "print(label_names)\n",
    "\n",
    "num_classes = 26\n",
    "y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "y_val = to_categorical(y_val, num_classes=num_classes)\n",
    "y_test = to_categorical(y_test, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Sj30oJrvilb"
   },
   "outputs": [],
   "source": [
    "# Define a function to create your VGG16 model with tunable hyperparameters\n",
    "def build_vgg16_model(input_shape=(224, 224, 3), num_classes=26, learning_rate=0.0001, num_dense_units=512):\n",
    "    vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    for layer in vgg16_base.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    flatten_layer = Flatten()(vgg16_base.output)\n",
    "    dense_layer = Dense(num_dense_units, activation='relu')(flatten_layer)\n",
    "    output_layer = Dense(num_classes, activation='softmax')(dense_layer)\n",
    "\n",
    "    model = Model(inputs=vgg16_base.input, outputs=output_layer)\n",
    "\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Build the VGG16 model\n",
    "vgg_model = build_vgg16_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7KXgUNovoBg"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8HnQr1zuvrAJ"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.applications import VGG16\n",
    "from sklearn.metrics import f1_score, make_scorer\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class KerasModel(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, learning_rate=0.0001, num_dense_units=512):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_dense_units = num_dense_units\n",
    "        self.model = self.build_model()\n",
    "\n",
    "    def build_model(self):\n",
    "        vgg16_base = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "        for layer in vgg16_base.layers:\n",
    "            layer.trainable = False\n",
    "\n",
    "        flatten_layer = Flatten()(vgg16_base.output)\n",
    "        dense_layer = Dense(self.num_dense_units, activation='relu')(flatten_layer)\n",
    "        output_layer = Dense(26, activation='softmax')(dense_layer)\n",
    "\n",
    "        model = Model(inputs=vgg16_base.input, outputs=output_layer)\n",
    "\n",
    "        optimizer = Adam(learning_rate=self.learning_rate)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        print(\"Fitting model...\")\n",
    "        self.model.fit(X, y, verbose=0)  # Set verbose to 0 to suppress output\n",
    "        print(\"Model fitted.\")\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Predicting...\")\n",
    "        predictions = np.argmax(self.model.predict(X), axis=1)\n",
    "        print(\"Prediction completed.\")\n",
    "        return predictions\n",
    "\n",
    "# Define hyperparameters to search\n",
    "learning_rate = [0.0001, 0.001, 0.01]\n",
    "num_dense_units = [256, 512, 1024]\n",
    "\n",
    "param_distributions = {\n",
    "    'learning_rate': learning_rate,\n",
    "    'num_dense_units': num_dense_units\n",
    "}\n",
    "\n",
    "# Create a custom scorer for macro F1 score\n",
    "def macro_f1(y_true, y_pred):\n",
    "    return f1_score(y_true, y_pred, average='macro')\n",
    "\n",
    "macro_f1_scorer = make_scorer(macro_f1)\n",
    "\n",
    "# Create Keras model wrapper\n",
    "keras_model = KerasModel()\n",
    "\n",
    "# Perform random search with macro F1 score as the evaluation metric\n",
    "print(\"Starting random search...\")\n",
    "random_search = RandomizedSearchCV(estimator=keras_model, param_distributions=param_distributions, n_iter=10, cv=3, scoring=macro_f1_scorer, verbose=0)\n",
    "random_search_result = random_search.fit(x_train, y_train)\n",
    "\n",
    "# Print best hyperparameters and results\n",
    "print(\"Best macro F1 score: %f using %s\" % (random_search_result.best_score_, random_search_result.best_params_))\n",
    "\n",
    "# Get the best model\n",
    "best_model = random_search_result.best_estimator_.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XZTzujwnvujx"
   },
   "outputs": [],
   "source": [
    "# Summary of the model\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1QjBQxoHvu2m"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# Initialize an empty list to store the metrics for each epoch\n",
    "data = []\n",
    "\n",
    "# Initialize an empty list to store the VGG predictions\n",
    "val_vgg_predictions = []\n",
    "test_vgg_predictions = []\n",
    "\n",
    "# Iterate over each epoch\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    # Train the model for one epoch\n",
    "    history = vgg_model.fit(x=x_train,\n",
    "                            y=y_train,\n",
    "                            epochs=1,  # Train for one epoch only\n",
    "                            batch_size=batch_size,\n",
    "                            validation_data=(x_val, y_val),\n",
    "                            verbose=0)  # Set verbose to 0 to suppress output\n",
    "\n",
    "    # Calculate metrics for this epoch\n",
    "    train_loss = history.history['loss'][0]\n",
    "    val_loss = history.history['val_loss'][0]\n",
    "    train_accuracy = history.history['accuracy'][0]\n",
    "    val_accuracy = history.history['val_accuracy'][0]\n",
    "\n",
    "    # Calculate F1 score for validation data\n",
    "    y_pred = vgg_model.predict(x_val)\n",
    "    macro_f1 = f1_score(y_val.argmax(axis=1), y_pred.argmax(axis=1), average='macro')\n",
    "\n",
    "    # Append the metrics to the list\n",
    "    data.append({'Epoch': epoch,\n",
    "                 'Train Loss': train_loss,\n",
    "                 'Val Loss': val_loss,\n",
    "                 'Train Accuracy': train_accuracy,\n",
    "                 'Val Accuracy': val_accuracy,\n",
    "                 'Macro F1 Score': macro_f1})\n",
    "\n",
    "    # Store VGG predictions for validation and test sets\n",
    "    val_vgg_predictions.append(best_model.predict(x_val))\n",
    "    test_vgg_predictions.append(best_model.predict(x_test))\n",
    "\n",
    "# Convert the list of dictionaries to a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# # Add VGG predictions as new columns to val_predictions_df and test_predictions_df\n",
    "# val_predictions_df['VGG Predictions'] = val_vgg_predictions\n",
    "# test_predictions_df['VGG Predictions'] = test_vgg_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laujlOANvxcv"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(vgg_model, 'vgg_model.pth')\n",
    "\n",
    "# Save the state dictionary\n",
    "torch.save(vgg_model.state_dict(), 'vgg_model_state_dict.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNSeOrnEvzM6"
   },
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yiTZ4VR_v1Gm"
   },
   "outputs": [],
   "source": [
    "# Download image arrays from S3\n",
    "X_train = download_from_s3(s3_bucket_name, \"rgb_npy/train/rgb_224x224_train.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "y_train = download_from_s3(s3_bucket_name, \"rgb_npy/train/rgb_labels_train.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "X_val = download_from_s3(s3_bucket_name, \"rgb_npy/val/rgb_224x224_val.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "y_val = download_from_s3(s3_bucket_name, \"rgb_npy/val/rgb_labels_val.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "X_test = download_from_s3(s3_bucket_name, \"rgb_npy/test/rgb_224x224_test.npy\", aws_access_key_id, aws_secret_access_key)\n",
    "y_test = download_from_s3(s3_bucket_name, \"rgb_npy/test/rgb_labels_test.npy\", aws_access_key_id, aws_secret_access_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vjfNhvkVv3PO"
   },
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bx7NZwgov5Fj"
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.1, 0.3, 0.5],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize XGBoost classifier\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=26)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', verbose=2, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters from grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "# Train the model with best parameters\n",
    "best_xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=num_classes, **best_params)\n",
    "best_xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model weights\n",
    "model_filename = \"workspace/capstone-efficient-waste-sorting-2024/best_xgb_model.pkl\"\n",
    "joblib.dump(best_xgb_model, model_filename)\n",
    "print(\"Model saved as\", model_filename)\n",
    "\n",
    "# Predict on validation set\n",
    "val_pred = best_xgb_model.predict(X_val)\n",
    "\n",
    "# Calculate accuracy and macro F1 score on validation set\n",
    "val_accuracy = accuracy_score(y_val, val_pred)\n",
    "val_f1_macro = f1_score(y_val, val_pred, average='macro')\n",
    "print(\"Validation Accuracy:\", val_accuracy)\n",
    "print(\"Validation Macro F1 Score:\", val_f1_macro)\n",
    "\n",
    "# Predict on test set\n",
    "test_pred = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and macro F1 score on test set\n",
    "test_accuracy = accuracy_score(y_test, test_pred)\n",
    "test_f1_macro = f1_score(y_test, test_pred, average='macro')\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "print(\"Test Macro F1 Score:\", test_f1_macro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlnwkAYJWvA9"
   },
   "source": [
    "## Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTv2hnpEv6sl"
   },
   "outputs": [],
   "source": [
    "# THIS IS FROM AN OLD IMPLEMENTATION, THIS CODE WILL WORK IF YOU ADD A CELL BEFORE THIS WHERE YOU IMPORT THE SAVED MODELS THAT WERE\n",
    "# SAVED EARLIER IN THIS CODE AND APPLY THEM TO THE VALIDATION AND TEST SETS. THEN YOU CAN PUT THE PREDICTIONS AS 3 COLUMNS WITH THE ROWS\n",
    "# BEING THE NUMBER OF ROWS IN THE VALIDATION OR TEST SETS RESPECTIVELY AND RUN THE BELOW CODE TO VOTE.\n",
    "\n",
    "# from collections import Counter\n",
    "# from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "\n",
    "# # Function to find the most common prediction in each row\n",
    "# def get_final_prediction(row):\n",
    "#     prediction_counts = Counter(row)\n",
    "#     most_common_prediction = prediction_counts.most_common(1)[0][0]\n",
    "#     return most_common_prediction\n",
    "\n",
    "# # Get final predictions for validation and test datasets\n",
    "# val_predictions_df['Final Prediction'] = val_predictions_df.apply(get_final_prediction, axis=1)\n",
    "# test_predictions_df['Final Prediction'] = test_predictions_df.apply(get_final_prediction, axis=1)\n",
    "\n",
    "# # Calculate confusion matrices, macro F1 scores, and accuracy for validation dataset\n",
    "# val_conf_matrix = confusion_matrix(y_val, val_predictions_df['Final Prediction'])\n",
    "# val_macro_f1 = f1_score(y_val, val_predictions_df['Final Prediction'], average='macro')\n",
    "# val_accuracy = accuracy_score(y_val, val_predictions_df['Final Prediction'])\n",
    "\n",
    "# # Calculate confusion matrices, macro F1 scores, and accuracy for test dataset\n",
    "# test_conf_matrix = confusion_matrix(y_test, test_predictions_df['Final Prediction'])\n",
    "# test_macro_f1 = f1_score(y_test, test_predictions_df['Final Prediction'], average='macro')\n",
    "# test_accuracy = accuracy_score(y_test, test_predictions_df['Final Prediction'])\n",
    "\n",
    "# # Print confusion matrices, macro F1 scores, and accuracy for validation and test datasets\n",
    "# print(\"Validation Confusion Matrix:\")\n",
    "# print(val_conf_matrix)\n",
    "# print(\"Validation Macro F1 Score:\", val_macro_f1)\n",
    "# print(\"Validation Accuracy:\", val_accuracy)\n",
    "\n",
    "# print(\"\\nTest Confusion Matrix:\")\n",
    "# print(test_conf_matrix)\n",
    "# print(\"Test Macro F1 Score:\", test_macro_f1)\n",
    "# print(\"Test Accuracy:\", test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
